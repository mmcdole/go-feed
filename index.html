<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Archi &amp; techno &#8211; OCTO talks !</title>
	<atom:link href="http://blog.octo.com/category/architecture-et-technologies/feed/" rel="self" type="application/rss+xml" />
	<link>http://blog.octo.com/</link>
	<description>Le blog d&#039;OCTO Technology, cabinet d&#039;architectes en systèmes d&#039;information</description>
	<lastBuildDate>Fri, 15 Apr 2016 14:18:56 +0000</lastBuildDate>
	<language>fr-FR</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.4.2</generator>
	<item>
		<title>Nous étions à la KubeCon Europe (2/2)</title>
		<link>http://blog.octo.com/nous-etions-a-la-kubecon-europe-22/</link>
		<comments>http://blog.octo.com/nous-etions-a-la-kubecon-europe-22/#respond</comments>
		<pubDate>Fri, 15 Apr 2016 12:08:34 +0000</pubDate>
		<dc:creator><![CDATA[Etienne Coutaud]]></dc:creator>
				<category><![CDATA[Archi & techno]]></category>
		<category><![CDATA[Infrastructure et opérations]]></category>
		<category><![CDATA[CaaS]]></category>
		<category><![CDATA[CI]]></category>
		<category><![CDATA[CNCF]]></category>
		<category><![CDATA[HA]]></category>
		<category><![CDATA[Kubernetes]]></category>
		<category><![CDATA[monitoring]]></category>
		<category><![CDATA[namespace]]></category>
		<category><![CDATA[OpenShift]]></category>
		<category><![CDATA[PaaS]]></category>
		<category><![CDATA[SDN]]></category>
		<category><![CDATA[Storage]]></category>
		<category><![CDATA[Test]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=61031</guid>
		<description><![CDATA[Kubernetes et son écosystème pour la production La KubeCon n’était pas que l’occasion de présenter la roadmap et les nouvelles fonctionalités de Kubernetes. C’était aussi l’occasion de faire le point sur son écosystème grandissant et sur son utilisation en production. Pour être serein en production, nous nous attendons à ce qu’un framework comme Kubernetes propose [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/nous-etions-a-la-kubecon-europe/" rel="bookmark" title="Nous étions à la KubeCon Europe (1/2)">Nous étions à la KubeCon Europe (1/2) </a></li>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<h1>Kubernetes et son écosystème pour la production</h1>
<p>La KubeCon n’était pas que l’occasion de présenter la roadmap et <a href="http://blog.octo.com/nous-etions-a-la-kubecon-europe/">les nouvelles fonctionalités de Kubernetes</a>. C’était aussi l’occasion de faire le point sur son écosystème grandissant et sur son utilisation en production.</p>
<p><span style="line-height: 1.5;">Pour être serein en production, nous nous attendons à ce qu’un framework comme Kubernetes propose :</span></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">Une installation automatisée et idempotente</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Du cloisonnement d’environnement (Multitenant)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">De la persistence sur les données</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Du monitoring</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">De la haute disponibilité</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Du Continuous Intégration et du Continuous Delivery</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Des stratégies de tests d’intégration</span></li>
</ul>
<p>C&rsquo;est l&rsquo;ensemble de ces aspects traités pendant les conférences que nous allons développer dans la suite de cet article.</p>
<p><span id="more-61031"></span></p>
<h1>Kubernetes c&rsquo;est bien beau mais comment je l&rsquo;installe chez moi ?</h1>
<p><span style="font-weight: 400;">De l’aveux même de </span><a href="https://kubeconeurope2016.sched.org/speaker/kelseyhightower2"><span style="font-weight: 400;">Kelsey Hightower</span></a><span style="font-weight: 400;">, le plus difficile est d’installer Kubernetes. Son utilisation est faite pour être simple et “automagique”. Les playbooks/recettes/scripts d’installation sont de plus en plus nombreux, nous retiendrons notamment <a href="https://docs.kubespray.io">Kubespray</a></span><span style="font-weight: 400;">. Ce playbook Ansible permet d’installer un cluster Kubernetes déjà packagé avec ses dépendances, il fonctionne sur plusieurs distributions, et permet d’embarquer simplement les plugins third party de votre choix.</span></p>
<h1>Tout le monde sur un seul cluster ? Mes projets risquent ils de se marcher dessus ?</h1>
<p>Kubernetes seul ne propose pas de solutions permettant de cloisonner différents namespaces. Tous les conteneurs peuvent communiquer ensemble. Pour répondre au besoin du cloisonnement, des solutions de SDN (Software Defined Networking) dédiées à Kubernetes (ou pas) se sont multipliées ces derniers mois.</p>
<p>Deux types de solutions rentrent en concurrence :</p>
<ol>
<li style="font-weight: 400;"><span style="font-weight: 400;">Les solutions overlay</span></li>
</ol>
<ol>
<ol>
<li style="font-weight: 400;"><b>Nuage Network </b><span style="font-weight: 400;">s’appuie sur ce modèle qui permet le cloisonnement inter et intra namespaces. La solution se veut simple : la configuration se fait en définissant la politique de sécurité dans une interface dédiée. Le point fort de cette solution : elle ne se cantonne pas à Kubernetes, puisqu’elle fonctionne également avec Openshift v3, mais aussi avec OpenStack, VMware, et rend possible la fédération de tous ces environnements.</span></li>
<li style="font-weight: 400;"><b>OpenContrail </b><span style="font-weight: 400;">suit la lignée de Nuage Network mais remplace Open vSwitch par un vRouter fait maison. Le fonctionnement et les points forts sont quasiment similaires : une configuration par GUI qui se veut simple, et qui fonctionne avec Kubernetes, Openshift v3,  OpenStack et VMware. Cette solution à l’avantage d’être open source et utilisable sans licence.</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;"><strong>Openshift-SDN</strong> est une solution de même type, dédiée cette fois-ci à Openshift v3. Le projet est jeune, permet le cloisonnement entre les différents namespaces Openshift par le biais d’une ligne de commande. La solution est nativement intégrée à Openshift mais pose certaines contraintes comme l’incapacité de fermer un flux ouvert entre deux projets.</span></li>
</ol>
</ol>
<p><img class="aligncenter wp-image-61058 size-large" src="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-30-a-13-54-56-1024x238.png" alt="Capture d’écran 2016-03-30 à 13.54.56" width="640" height="149" srcset="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-30-a-13-54-56-300x70.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-30-a-13-54-56-1024x238.png 1024w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-30-a-13-54-56.png 1498w" sizes="(max-width: 640px) 100vw, 640px" /></p>
<ol>
<li style="font-weight: 400;"><span style="font-weight: 400;">Les solutions de pur niveau 3 qui remplacent Open vSwitch par un Virtual Router ou directement par iptables :</span></li>
</ol>
<ol>
<ol>
<li style="font-weight: 400;"><span style="font-weight: 400;"><strong>Romana</strong> est un acteur récent, qui pousse le principe de </span><a href="http://romana.io/cloud/cloud_native_networks/"><span style="font-weight: 400;">Cloud Native SDN</span></a><span style="font-weight: 400;">. Leur objectif est de supprimer la complexité des configurations Overlay, en s’appuyant sur des règles de routages statiques. L’apport de leur solution (qui fonctionne sur Kubernetes et OpenStack) est la simplicité d’architecture (plus simple à troubleshooter), la performance et la segmentation. La configuration se fait via le CLI de Kubernetes. </span><a href="http://fr.slideshare.net/RomanaProject/kubecon-london-2016-ronana-cloud-native-sdn"><span style="font-weight: 400;">Slides de leur présentation.</span></a></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Le </span><strong><a href="https://www.projectcalico.org/">Projet Calico</a> </strong><span style="font-weight: 400;">poursuit sa montée en puissance. L’objectif de cette solution est d’offrir simplicité d’exploitation, forte scalabilité et sécurité, en utilisant les mécanismes de routages directement intégrés dans le noyau Linux. L’utilisation est similaire à Romana puisqu’elle se fait directement via le CLI, ou par la configuration d’objets Kubernetes.</span></li>
</ol>
</ol>
<p><img class="aligncenter wp-image-61061 size-medium" src="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-30-a-13-55-06-300x114.png" alt="Capture d’écran 2016-03-30 à 13.55.06" width="300" height="114" srcset="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-30-a-13-55-06-300x114.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-30-a-13-55-06.png 974w" sizes="(max-width: 300px) 100vw, 300px" /></p>
<p><span style="font-weight: 400;">Si les promesses de Calico et Romana sont à prendre au sérieux et doivent être explorées, c’est plutôt du côté d’OpenContrail et de Nuage Network, les plus expérimentés, que nous nous tournerons pour notre production à court termes.</span></p>
<h1>Vous m&rsquo;avez dit qu&rsquo;un conteneur est volatile et éphémère, quid de mes bases de données ?</h1>
<p>Une des problématiques majeure liée à l’utilisation de conteneurs en production est la persistance des données. En effet par définition un conteneur est éphémère et non persistant.</p>
<p>La solution poussée par Kubernetes est l’utilisation des Persistent Volume.</p>
<p><span style="font-weight: 400;">Le cycle de vie est le suivant : </span></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">L&rsquo;administrateur du cluster Kubernetes définit un certain nombre de PV (Persistent Volume), ces PV sont caractérisés par :</span>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">La taille de l’espace disque mis à disposition</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Le mode d&rsquo;accès (ReadWriteOnce/ReadWriteMany)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Le système de stockage (Ceph, GlusterFS, NFS, local, etc … )</span></li>
</ul>
</li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Les applications font des requêtes de stockage via un PVC (Persistent Volume Claim), caractérisé par :</span>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">L’espace disque souhaité</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Le mode d’accès</span></li>
</ul>
</li>
</ul>
<p><span style="font-weight: 400;">Les mécanismes internes de Kubernetes font ensuite le mapping entre les PV et les PVC permettant ainsi d’abstraire complètement pour les pods le système de stockage sous-jacent.</span></p>
<p><img class="aligncenter wp-image-61063 size-large" src="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-10-09-21-1024x637.png" alt="Capture d’écran 2016-03-29 à 10.09.21" width="640" height="398" srcset="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-10-09-21-300x187.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-10-09-21-1024x637.png 1024w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-10-09-21.png 1234w" sizes="(max-width: 640px) 100vw, 640px" /></p>
<h1>Comment respire ma plateforme ?</h1>
<p><span style="font-weight: 400;">Bien connu dans la gestion des réseaux des conteneurs, Weave a présenté sa solution de monitoring ou plutôt, de visualisation d’architecture de type microservice : </span><a href="https://www.weave.works/products/weave-scope/"><span style="font-weight: 400;">Weave Scope</span></a><span style="font-weight: 400;">. Intuitif, cette solution propose une cartographie des conteneurs (Docker), des process et du host. Une solution sous licence Apache 2.0 à suivre pour Kubernetes.</span></p>
<p><span style="font-weight: 400;">Autre solution, présente sur les stands de la KubeCon, </span><a href="https://www.datadoghq.com/"><span style="font-weight: 400;">Datadog</span></a><span style="font-weight: 400;"> présente un modèle en SaaS. Des agents sont installés sur les différents hosts qui remontent leurs métriques. Les dashboards sont à configurer, allant du plus simple au plus complexe, en allant piocher dans un catalogue de “briques monitorables”. Si la solution est complète, il faudra débourser une quinzaine d’euros par agent, relativement abordable compte tenu du service rendu.</span></p>
<p><span style="font-weight: 400;">Enfin, une solution qui s’adresse aux utilisateurs de shell et de la CLI Kubernetes : </span><a href="http://www.sysdig.org/"><span style="font-weight: 400;">Sysdig</span></a><span style="font-weight: 400;">. Cette solution est l’equivalent de la commande “top” dans un shell. Elle permet de visualiser directement en ligne de commande : la consommation CPU, RAM des conteneurs sur le cluster, l’état des conteneurs et bien d’autres métriques.</span></p>
<h1>J’ai besoin de haute disponibilité, quelles solutions s&rsquo;offrent à moi ?</h1>
<p>La haute disponibilité se décline sous plusieurs aspects et peut être gérée sur différentes applications de la stack. Principalement deux niveaux de HA ont été abordés lors des conférences : la haute disponibilité des bases de données, et celle dans Kubernetes</p>
<p><span style="font-weight: 400;">Deux solutions ont été présentées pour assurer le HA des bases de données :  </span></p>
<ul>
<li style="font-weight: 400;"><a href="http://vitess.io/overview/"><span style="font-weight: 400;">vitess.io</span></a><span style="font-weight: 400;"> permettant de monter un cluster de MySQL</span></li>
</ul>
<p><img class="aligncenter wp-image-61064 size-full" src="http://blog.octo.com/wp-content/uploads/2016/03/vitessoverview.png" alt="VitessOverview" width="873" height="447" srcset="http://blog.octo.com/wp-content/uploads/2016/03/vitessoverview-300x154.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/vitessoverview.png 873w" sizes="(max-width: 873px) 100vw, 873px" /></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;"><a href="https://github.com/zalando/patroni">Patroni</a> </span><span style="font-weight: 400;">: Une solution opensource développée par Zalando permettant de créer un cluster PostgreSQL en utilisant Zookeeper ou ETCD.</span></li>
</ul>
<p>Le mécanisme de HA natif à Kubernetes est le  ReplicationController. Il permet de s’assurer qu’à tout instant un pod est opérationnel. Si par exemple le niveau de réplication est défini à 2 dans le Replication Controller, Kubernetes va s’assurer que le contrat est bien rempli et va relancer un pod si l’un venait à tomber pour s’assurer que 2 pods sont bien opérationnels.</p>
<p>Une autre fonctionnalité qui a été présentée est le déploiement en mode RollingUpdate. Ce mode de déploiement est similaire à un blue/green deployment au niveau des pods</p>
<h1>Et mes pipelines d’intégration et de déploiement continue ?</h1>
<p>Le sujet du Continuous Integration / Continuous Delivery a été abordé avec le retour d’expérience de <a href="https://kubeconeurope2016.sched.org/speaker/michael.ward1">Michael Ward</a> de Pearson. Avec plus de 400 équipes de développement partout dans le monde, Pearson doit délivrer très fréquemment des pipelines de CI/CD, tout en conservant les tests de sécurité, de performance et d’assurance qualité. La clé de leur succès est de considérer les pipelines comme du bétail (cattle vs pets pattern). Ces méthodes ont permis de faire économiser aux développeurs 10% de leurs temps.</p>
<p>Pour allier leurs contraintes avec une grande vélocité, plusieurs solutions ont été mises en place :</p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">Les conteneurs de base ont été standardisés</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Les exigences de sécurité ont été intégrés aux images</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Le pipeline de build intègre tous les tests de QA, sécurité et performance</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Les boucles de feedback ont été réduites entre les dev et les OPS</span></li>
</ul>
<p><span style="font-weight: 400;">Chaque développeur doit pouvoir déployer son pipeline, il n’est plus question de n’avoir qu’une personne dans l’équipe responsable de sa construction. Pour faciliter le processus de construction, Pearson s’appuie sur du ChatOps : Une communication avec un hubot permet de créer un repository bitbucket automatiquement, déploie un pipeline Jenkins… Tout l’écosystème est créé à partir d’une ligne de chat.</span></p>
<blockquote class="twitter-tweet" data-width="550"><p lang="und" dir="ltr"><a href="https://twitter.com/hashtag/chatops?src=hash">#chatops</a> <a href="https://twitter.com/pearson">@pearson</a> via <a href="https://twitter.com/DevoperandI">@DevoperandI</a> <a href="https://twitter.com/kubeconio">@kubeconio</a> <a href="https://t.co/vDahYWbV38">pic.twitter.com/vDahYWbV38</a></p>
<p>&mdash; Chris Jackson (@chriswiggy) <a href="https://twitter.com/chriswiggy/status/708242403258462208">March 11, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>Enfin, pour décrire un environnement, les développeurs doivent fournir une fichier yaml décrivant:</p>
<ul>
<li>L’environnement courant (ex : development)</li>
<li>Le next environnement  (ex : staging)</li>
<li>La méthode de déploiement Kubernetes (ex : Rolling Upgrade pour un déploiement en zero downtime)</li>
<li>Le repository et sa branche</li>
<li>Les commandes à effectuer lors du build (ex : rake db:migrate)</li>
</ul>
<p><a href="https://apprenda.com">Apprenda</a>, qui a décidé d’intégrer Kubernetes à son offre pour un meilleur support des Cloud Native Application, aborde également le sujet du CI/CD. Leur objectif est de proposer un PaaS capable d’héberger les applications legacy / monolithiques, et les cloud native applications. L’utilisation d’une plateforme de CI/CD capable d’orchestrer le déploiement d’applications hybrides (leur démo s’appuie sur UrbanCode) est une première étape qui permet de répondre à la problématique du déploiement. Les problèmes ne sont pas tous résolus et notamment le fait que :</p>
<ul>
<li>Le pipeline de déploiement doit être régénéré à chaque ajout/suppression de composant</li>
<li>Le déploiement va à la vitesse du composant le plus lent</li>
</ul>
<p><span style="font-weight: 400;">Leur solution est de créer une plateforme spécifique qui comprend les mécanismes des deux mondes, facilitant le déploiement et la communication des applications entre elles. Nous espérons qu’elle soit un jour reversée à la communauté.</span></p>
<h1>Comment tester rapidement mes applications ?</h1>
<p><span style="font-weight: 400;"><a href="https://kubeconeurope2016.sched.org/speaker/cyucel">Can Yücel</a>, ingénieur logiciel chez </span><span style="font-weight: 400;">LaunchPad Central est venu expliquer la stratégie de tests applicatif qu&rsquo;ils ont mis en place. Nous parlons bien de tests d’applications déployées sur Kubernetes et non des tests de l’infrastructure Kubernetes (les grands oubliés de cette KubeCon).</span></p>
<p><span style="font-weight: 400;">Kubernetes permet de déployer rapidement des applications, c’est cette propriété qui a été initialement utilisée chez LaunchPad. L’orchestration est la suivante :</span></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">Un cluster complet est construit</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Ce cluster contient les applications à tester</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Lorsque les tests sont tous bons le cluster est détruit</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Dans le cas inverse, il est conservé pour debugging</span></li>
</ul>
<p><span style="font-weight: 400;">Provisionner un cluster isolé pour du tests est une bonne pratique. Cependant la boucle de feedback peut être longue et cela nécessite d’avoir des machines à disposition.</span></p>
<blockquote><p>Comment réduire ma boucle de feedback ?</p></blockquote>
<blockquote class="twitter-tweet" data-width="550"><p lang="en" dir="ltr">&quot;namespace is a mechanism to partition resources created by users into a logically named group&quot; <a href="https://twitter.com/kubernetesio">@kubernetesio</a> <a href="https://twitter.com/hashtag/KubeCon?src=hash">#KubeCon</a></p>
<p>&mdash; Etienne Coutaud (@etiennecoutaud) <a href="https://twitter.com/etiennecoutaud/status/707972505781334016">March 10, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p><span style="font-weight: 400;">Les namespaces Kubernetes permettent de séparer logiquement les ressources au sein d’un même cluster. Ainsi il est recommandé de séparer chaque environnement d’un projet dans son namespace isolé. Grâce à cela, les tests sont exécutés sur le même cluster que la production, il n’est plus nécessaire d’avoir des machines dédiées au testing, la boucle de feedback est réduite.</span></p>
<h1>Suis je le seul sur Kubernetes ? Que font les autres ? qui norme ?</h1>
<p><span style="font-weight: 400;">La fondation <a href="https://cncf.io/">CNCF</a> (Cloud Native Computing Foundation) a été un sujet récurrent lors des deux jours de conférences. </span></p>
<p><span style="font-weight: 400;">L’objectif de cette fondation est de soutenir  et pousser l’adoption des technologies de conteneurisation, les architectures distribuées de type microservice, et l’automatisation de leur gestion.</span><br />
<span style="font-weight: 400;">Certaines tables rondes ont été faites pour discuter de la gouvernance autour des Cloud Native Applications, et de l’alignement des stratégies de contenerisation. La CNCF, fondée en Novembre 2015, a annoncé que Kubernetes est le premier projet à être intégré lors de la KubeCon 2016.</span></p>
<blockquote class="twitter-tweet" data-width="550"><p lang="en" dir="ltr">Just in time for <a href="https://twitter.com/hashtag/KubeCon?src=hash">#KubeCon</a>: “Cloud Native Computing Foundation Accepts Kubernetes as First Hosted Project”: <a href="https://t.co/x7SYFbnU1R">https://t.co/x7SYFbnU1R</a></p>
<p>&mdash; Alex Pollitt (@lxpollitt) <a href="https://twitter.com/lxpollitt/status/707928855865126913">March 10, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h2>Toutes les bonnes choses ont une fin &#8230;</h2>
<p>En conclusion, cette édition 2016 de la KubeCon a été riche en annonces, retours d&rsquo;expérience et démonstrations des outils gravitant dans l&rsquo;écosystème Kubernetes. OCTO Technology a pu ainsi conforter sa vision de l’intégration de ces outils chez ses clients.</p>
<p>Cet écosystème autour du conteneur est un changement de paradigme pour tous les acteurs de l’IT, du développeur à l’opérationnel. Même si cette technologie peux paraître difficile à mettre en place et à apprivoiser, la principale difficulté est le changement des organisations, des méthodologies et des processus. Comme l’a dit <a href="https://twitter.com/ipedrazas">Ivan Pedrazas</a> ‘It’s not a technology thing, it’s all about people”.</p>
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/nous-etions-a-la-kubecon-europe/" rel="bookmark" title="Nous étions à la KubeCon Europe (1/2)">Nous étions à la KubeCon Europe (1/2) </a></li>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/nous-etions-a-la-kubecon-europe-22/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Nous étions à la KubeCon Europe (1/2)</title>
		<link>http://blog.octo.com/nous-etions-a-la-kubecon-europe/</link>
		<comments>http://blog.octo.com/nous-etions-a-la-kubecon-europe/#respond</comments>
		<pubDate>Fri, 08 Apr 2016 15:48:44 +0000</pubDate>
		<dc:creator><![CDATA[Etienne Coutaud]]></dc:creator>
				<category><![CDATA[Infrastructure et opérations]]></category>
		<category><![CDATA[CaaS]]></category>
		<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Kubecon]]></category>
		<category><![CDATA[Kubernetes]]></category>
		<category><![CDATA[OpenShift]]></category>
		<category><![CDATA[PaaS]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=61041</guid>
		<description><![CDATA[The Kubernetes Community conference Nous y voyons plus clair, Kubernetes est pour le moment la solution de Container as a Service que nous recommandons. Nous l&#8217;avons déjà déployé en production, packagé avec Openshift Origin pour proposer une Platform as a Service du meilleur effet. C&#8217;est fort de notre expérience que nous avons voulu voir ce [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
<li><a href="http://blog.octo.com/nous-etions-a-la-kubecon-europe-22/" rel="bookmark" title="Nous étions à la KubeCon Europe (2/2)">Nous étions à la KubeCon Europe (2/2) </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<h2>The Kubernetes Community conference</h2>
<p>Nous y voyons plus clair, Kubernetes est pour le moment la solution de Container as a Service que <a href="http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/">nous recommandons</a>. Nous l&rsquo;avons déjà déployé en production, packagé avec Openshift Origin pour proposer une Platform as a Service du meilleur effet. C&rsquo;est fort de notre expérience que nous avons voulu voir ce qui se fait ailleurs, dans le monde des containers. Et quoi de mieux que la Kubecon Europe pour satisfaire notre soif d&rsquo;apprentissage&#8230;</p>
<p>La Kubecon Europe a eu lieu cette année à Londres et s’est déroulée les 10 et 11 mars 2016.</p>
<p><span style="font-weight: 400;"><img class="alignnone" src="https://alian.info/content/images/2016/02/0228_01.jpg" alt="" width="900" height="450" /></span></p>
<p><span style="font-weight: 400;">C&rsquo;est l’occasion de découvrir :</span></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">La vision et les nouveautés de Kubernetes 1.2 et 1.3</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">L’ensemble des solutions gravitant autour de l’écosystème Kubernetes</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Les retours d’expériences et différents cas d’usages</span></li>
</ul>
<p>Les grands thèmes abordés lors de cet événement ont été nombreux, nous avons pris le parti de nous concentrer sur deux sujets :</p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">La Roadmap et la vision de Kubernetes</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Kubernetes en production (qui fera l&rsquo;objet d&rsquo;un second article)</span></li>
</ul>
<p>Dans cet article, nous traiterons le premier point sur la vision et les nouveautés de Kubernetes qui nous ont été présentées. Il s&rsquo;adresse aux amateurs confirmés de Kubernetes.</p>
<p><span id="more-61041"></span></p>
<p>&nbsp;</p>
<h1>La vision et la roadmap et de Kubernetes</h1>
<blockquote><p><i><span style="font-weight: 400;">“Le entrypoint.sh dans docker c’est pour les hipsters” <a href="https://twitter.com/kelseyhightower" target="_blank">Kelsey Hightower</a></span></i></p></blockquote>
<p>Get started quicker, get big faster. C’est de cette manière que Kelsey Hightower a introduit la première keynote de la KubeCon 2016. Avant de lister les nouveautés à venir de Kubernetes, il convient de rappeler ce qu’est Kubernetes : <b>un framework permettant de construire un système distribué</b>. Il s’appuie sur les technologies de container qu’il sait orchestrer. Kubernetes est un <b>CaaS</b> (Container as a Service) <b>et non un PaaS (Platform as a Service)</b>.</p>
<blockquote class="twitter-tweet" data-width="550"><p lang="en" dir="ltr">&quot;Kubernetes is not a PAAS. You don&#39;t install it and end up with Heroku.&quot; <a href="https://twitter.com/hashtag/KubeCon?src=hash">#KubeCon</a> <a href="https://twitter.com/kelseyhightower">@kelseyhightower</a></p>
<p>&mdash; Michał Paluchowski (@mpaluchowski) <a href="https://twitter.com/mpaluchowski/status/707866052911374337">March 10, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p><span style="font-weight: 400;">Comme beaucoup de technologies avec le vent en poupe, ces dernières soulèvent de nouvelles problématiques, et de nouveaux usages apparaissent. Il n’est toutefois pas obligatoire de mettre son SI en chantier sous prétexte que Kubernetes va TOUT révolutionner.</span></p>
<p><span style="font-weight: 400;">Kelsey Hightower rappelle ainsi quelques bonnes pratiques émergentes, parmi lesquelles : </span></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">Il n’est pas obligatoire d’intégrer votre SI entier dans Kubernetes. Cela s’applique notamment aux bases de données relationnelles qui ne scalent pas simplement</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Kubernetes permet le versionnement des composants via les tags Docker, mais attention : le tag latest n’est pas une version ;)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">L’architecture de Kubernetes permet de scaler by design. Attention à ne pas en faire trop : si vous n’avez pas d’utilisateurs sur votre plateforme, vous n’êtes pas obligé de scaler tout de suite</span></li>
</ul>
<h1>Les nouveautées de Kubernetes 1.2 et 1.3</h1>
<p><span style="font-weight: 400;">La version 1.2 est désormais disponible </span></p>
<blockquote class="twitter-tweet" data-width="550"><p lang="en" dir="ltr">Kubernetes 1.2 has gone GA! Read the blog this week for coverage of five of the new features <a href="https://t.co/PJg7BHjBHv">https://t.co/PJg7BHjBHv</a></p>
<p>&mdash; Kubernetes (@kubernetesio) <a href="https://twitter.com/kubernetesio/status/714517066036826113">March 28, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p><span style="font-weight: 400;">Elle embarque les nouvelles fonctionnalités suivantes: </span></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">Une nouvelle interface</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">La simplification des flux entrants (Ingress), facilitant le routage vers les PODs depuis Internet</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">La gestion des secrets pour simplifier la configuration ssl des frontend</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Une meilleure scalabilité</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">L’ajout des ReplicasSet qui facilite entre autres les déploiements en rolling update et permet d’affiner la selection des objets à travers du CLI (exemple : je veux scaler tous mes frontaux de production)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">L’apparition d’une ConfigMap qui est un descripteur clé / valeur consommé par les pods au démarrage pour une configuration plus fine (l’équivalent d’un cloud init)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">La gestion automatique des clusters (génération de namespace; </span><span style="font-weight: 400;">management des secret et export des ressources)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">L’intégration simplifiée des extensions (Third Party)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Et bien d’autres features que vous retrouverez <a href="https://github.com/kubernetes/kubernetes/wiki/Release-1.2" target="_blank">ici</a></span></li>
</ul>
<p>La version 1.3 annoncée dans quelques semaines (où quelques semaines = O(16)) est en cours de développement et apportera :</p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;">Le support des applications legacy (cattle vs </span><b>pets</b><span style="font-weight: 400;">)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">La fédération des clusters (Ubernetes)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Une meilleur scalabilité, et l’autoscaling non plus des pods, mais des clusters</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">La gestion des identités et le contrôle d’accès</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">La gestion des jobs (Cron)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Un Public Cloud Dashboard qui permettra de lancer des nightly builds et mesurer les performances du cluster</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">And lots, lots more!</span></li>
</ul>
<h1>Ce que nous en pensons:</h1>
<p><span style="font-weight: 400;">Si nous faisons le focus sur nos besoins en production, les nouveautés les plus intéressantes sont la simplicité de configuration concernant la sécurité (les secrets), la gestion de la mise en production sans interruption (rolling update), et l’exposition des pods (via ingress). Ajoutons à cela la gestion des clusters simplifiées avec la gestion des identités, la facilité de scaler (autant les pods que les clusters), nous avons une solution de CaaS de plus en plus robuste et sécurisante pour un usage en production.</span></p>
<p><span style="font-weight: 400;">Le fait de mettre l’effort sur l’intégration des Third Party est dans la continuité. Cela nous permettra de rendre nos clusters multitenants, à défaut d’être proposé par Kubernetes.</span></p>
<p><span style="font-weight: 400;">En regardant de plus près, nous constatons que ces fonctionnalités sont déjà présentes pour la plupart dans Openshift Origin (La solution de PaaS de RedHat basée sur Kubernetes), l’ajout des ConfigMap est un autre exemple.</span></p>
<h2>Kubernetes new features vs Openshift Origin</h2>
<p><img class="wp-image-61027 size-large aligncenter" src="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-16-41-56-1024x317.png" alt="Capture d’écran 2016-03-29 à 16.41.56" width="640" height="198" srcset="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-16-41-56-300x93.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-16-41-56-1024x317.png 1024w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-03-29-a-16-41-56.png 1310w" sizes="(max-width: 640px) 100vw, 640px" /></p>
<p>La convergence des deux solutions est frappante, Openshift v3 ayant pour lui sa capacité de Builder des projets. Il restera à voir l’évolution des solutions au dessus de Kubernetes, qui devront choisir de s’adapter, ou non, aux évolutions apportées par la communauté Kubernetes.</p>
<p>Rappelons-le, Kubernetes est un framework, plus spécifiquement un CaaS. C’est aussi un écosystème en pleine expansion sur lequel s’appuie de nombreux acteurs. Ces derniers s’appuient sur cette solution pour fabriquer leur PaaS, ou cherchent à le rendre robuste et scalable, pour une utilisation de plus en plus demandée par les entreprises en production. Nous aborderons l&rsquo;ensemble de ces pratiques et uses cases de Kubernetes en production dans le prochain article.</p>
<p style="text-align: left;">
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
<li><a href="http://blog.octo.com/nous-etions-a-la-kubecon-europe-22/" rel="bookmark" title="Nous étions à la KubeCon Europe (2/2)">Nous étions à la KubeCon Europe (2/2) </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/nous-etions-a-la-kubecon-europe/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>La Ruée vers le conteneur</title>
		<link>http://blog.octo.com/la-ruee-vers-le-conteneur/</link>
		<comments>http://blog.octo.com/la-ruee-vers-le-conteneur/#respond</comments>
		<pubDate>Thu, 24 Mar 2016 14:18:46 +0000</pubDate>
		<dc:creator><![CDATA[Victor Mignot]]></dc:creator>
				<category><![CDATA[Infrastructure et opérations]]></category>
		<category><![CDATA[CaaS]]></category>
		<category><![CDATA[container]]></category>
		<category><![CDATA[conteneur]]></category>
		<category><![CDATA[DevOps]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Kubernetes]]></category>
		<category><![CDATA[OpenShift]]></category>
		<category><![CDATA[rancher]]></category>
		<category><![CDATA[swarm]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=60852</guid>
		<description><![CDATA[Les conteneurs sont de toutes les réflexions aujourd’hui. De fait, un nombre croissant de projets d’orchestration voient le jour, essayant de répondre aux problématiques du Container as a Service (CaaS) et du conteneur en production. L’une des réponses précédemment présentées est OpenShift, une autre est Rancher. Cet article a pour but de vous présenter Rancher, et [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/" rel="bookmark" title="Docker en production : la bataille sanglante des orchestrateurs de conteneurs">Docker en production : la bataille sanglante des orchestrateurs de conteneurs </a></li>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/nous-etions-a-la-kubecon-europe/" rel="bookmark" title="Nous étions à la KubeCon Europe (1/2)">Nous étions à la KubeCon Europe (1/2) </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p><span style="font-weight: 400;">Les conteneurs sont de toutes les réflexions aujourd’hui. De fait, un nombre croissant de projets d’orchestration voient le jour, essayant de répondre aux problématiques du </span><b>Container as a Service (CaaS)</b><span style="font-weight: 400;"> et du </span><a href="http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/">conteneur en production</a><span style="font-weight: 400;">. L’une des <a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/">réponses précédemment présentées est OpenShift</a></span><span style="font-weight: 400;">, une autre est </span><b>Rancher</b>.</p>
<p><span style="font-weight: 400;">Cet article a pour but de vous présenter Rancher, et de balayer l’ensemble des fonctionnalités du produit. Il s’adresse à une population familière avec Docker, se posant la question de l’orchestration de conteneurs.</span></p>
<p><img class="aligncenter size-full wp-image-60856" src="http://blog.octo.com/wp-content/uploads/2016/03/rancher-cloud.png" alt="rancher-cloud" width="70" height="90" /><span id="more-60852"></span></p>
<h1><span style="font-weight: 400;">Que propose Rancher ?</span></h1>
<p><span style="font-weight: 400;">Rancher propose une plate-forme où il est possible de démarrer des conteneurs, sur divers environnements de manière isolée, résiliente et distribuée. Le tout emballé dans le but d’une mise en place et une utilisation simple : on provisionne des hôtes, sur lesquels vont se déployer des conteneurs.</span></p>
<p><span style="font-weight: 400;">Dès la première page de sa documentation, Rancher annonce ses ambitions : “une plate-forme open-source qui met à disposition des mécanismes spécialement conçus pour le fonctionnement de conteneurs en production”. Tout un programme.</span></p>
<p><span style="font-weight: 400;">Réussir ce pari, c’est résoudre </span><i><span style="font-weight: 400;">a minima</span></i><span style="font-weight: 400;"> les problématiques de :</span></p>
<ul>
<li style="font-weight: 400;"><span style="font-weight: 400;"><span style="text-decoration: underline;">Réseau</span> : faire communiquer entre eux des éléments volatiles, de manière sécurisée et le plus étanche possible aux dysfonctionnements</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;"><span style="text-decoration: underline;">Stockage</span> : le stockage sur un conteneur n’est par défaut pas persistant</span></li>
<li style="font-weight: 400;"><span style="text-decoration: underline;"><i><span style="font-weight: 400;">Load-balancing</span></i></span><span style="font-weight: 400;"> (répartiteur de charge) : s&rsquo;abstraire du nombre de conteneurs et de leur éphémérité en n’ayant qu’un seul point d’entrée pour un service donné</span></li>
<li style="font-weight: 400;"><span style="text-decoration: underline;"><span style="font-weight: 400;">S</span><i><span style="font-weight: 400;">ervice discovery</span></i></span><span style="font-weight: 400;"> (découverte de services) : être capable de </span><i><span style="font-weight: 400;">scaler</span></i><span style="font-weight: 400;"> en cas d&rsquo;un changement de charges ou de capacité (perte d’un hôte, d’un conteneur)</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;"><span style="text-decoration: underline;">Gestion des ressources</span> : ajouter des hôtes à votre </span><i><span style="font-weight: 400;">pool</span></i><span style="font-weight: 400;">, qu’ils soient situés dans votre salle serveurs, ou sur un cloud public</span></li>
</ul>
<p><span style="font-weight: 400;">Certains de ces points sont adressés par Docker, mais nous sommes capables de dire aujourd’hui que cela est incomplet, preuve en est la prolifération de projets d&rsquo;orchestration de conteneurs comme <a href="http://kubernetes.io/">Kubernetes</a>, <a href="https://www.openshift.com/">OpenShift</a>, <a href="https://mesosphere.github.io/marathon/">Marathon</a> (Mesos), <a href="https://www.nomadproject.io/">Nomad</a> ou <a href="http://rancher.com">Rancher</a>.</span></p>
<p><span style="font-weight: 400;">Rancher n’est pas à confondre avec RancherOS, développé en parallèle par Rancher Labs. Ce système d’exploitation est comparable à <a href="http://blog.octo.com/a-la-decouverte-de-coreos/">CoreOS</a> . Il contient le minimum nécessaire pour faire fonctionner Docker, packagé dans une image de 20 Mb.</span></p>
<p><img class="aligncenter size-full wp-image-60856" src="http://blog.octo.com/wp-content/uploads/2016/03/rancher-cloud.png" alt="rancher-cloud" width="70" height="90" /></p>
<h1><span style="font-weight: 400;">Un “poor lonesome cowboy” ?</span></h1>
<p><span style="font-weight: 400;"><img class="alignleft size-thumbnail wp-image-60895" src="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-02-25-a-19-12-04-150x150.png" alt="rancher-kubernetes" width="150" height="150" srcset="http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-02-25-a-19-12-04-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-02-25-a-19-12-04-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-02-25-a-19-12-04-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-02-25-a-19-12-04-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/03/capture-decran-2016-02-25-a-19-12-04-128x128.png 128w" sizes="(max-width: 150px) 100vw, 150px" />Face à Docker (Swarm/UCP), Google (Kubernetes), ou RedHat (OpenShift), Rancher fait figure de challenger. Mais les acteurs de ce projet n’en sont pas à leur coup d’essai, et disposent d’une expérience dans le </span><i><span style="font-weight: 400;">cloud computing</span></i><span style="font-weight: 400;">. Les fondateurs ont initié Cloud.com, racheté par Citrix.</span></p>
<p><span style="font-weight: 400;">Ceci mis à part, la stratégie choisie n’est pas de concurrencer frontalement ces solutions, mais de s’en servir pour alimenter son offre, tout en se rendant attractif en comblant leurs manques et en offrant une couche d’abstraction pour faciliter l’exploitation. Pour preuve, si Rancher propose une solution d’orchestration de conteneurs “maison” du nom de Cattle, Rancher intègre la possibilité de la remplacer par Swarm ou Kubernetes.</span></p>
<p><img class="aligncenter size-full wp-image-60856" src="http://blog.octo.com/wp-content/uploads/2016/03/rancher-cloud.png" alt="rancher-cloud" width="70" height="90" /></p>
<h1><span style="font-weight: 400;">Les promesses</span></h1>
<p><span style="font-weight: 400;">Créez et exploitez votre CaaS privé. Cela signifie laisser l’utilisateur déployer lui-même son application, en piochant dans une réserve de ressources préparée par les équipes d’infrastructure et mise à sa disposition. L’utilisateur est celui qui a la main sur la politique de déploiement de son application, laissant à Rancher le soin d’abstraire les services nécessaires (de calcul, de réseau, de stockage…) parmi tous les hôtes auxquels il a accès.</span></p>
<p><span style="font-weight: 400;">Un hôte peut être n’importe quel serveur (physique ou virtuel) sur lequel est capable de fonctionner Docker 1.9.1+. Ajouter un hôte à un </span><i><span style="font-weight: 400;">cluster</span></i><span style="font-weight: 400;"> Rancher est simple comme lancer un conteneur. Voilà dans l’idée.</span></p>
<h3><span style="font-weight: 400;">Présentation des fonctionnalités</span></h3>
<p><span style="font-weight: 400;">Rancher est capable de provisionner nativement des hôtes sur de nombreuses plateformes (ex : AWS, Rackspace, ….), avec une intégration fine des API de ces fournisseurs.</span></p>
<p><span style="font-weight: 400;">Sur ceux-ci, l’installation de la “tuyauterie” est automatique et paramétrable. Par exemple, la suppression d’une instance EC2 dans l’interface de Rancher le décommissionnera de votre compte AWS. En dehors des hébergeurs supportés, un hôte peut être à peu près n’importe quel serveur.</span></p>
<p><span style="font-weight: 400;">Rancher crée un réseau virtuel privé par environnement, assurant une communication entre les hôtes étanche et sécurisée grâce à un tunnel IPSec. L’intérêt est de se retrouver avec une série d’hôtes de provenances diverses (datacenter, cloud privé, cloud public, …), capables de communiquer comme s’ils se trouvaient sur un seul et même réseau local privé.</span></p>
<p><img class="aligncenter wp-image-60861 size-large" src="http://blog.octo.com/wp-content/uploads/2016/03/rancher-multi-cloud-1024x664.png" alt="rancher-multi-cloud" width="640" height="415" srcset="http://blog.octo.com/wp-content/uploads/2016/03/rancher-multi-cloud-300x195.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/rancher-multi-cloud-1024x664.png 1024w, http://blog.octo.com/wp-content/uploads/2016/03/rancher-multi-cloud.png 1108w" sizes="(max-width: 640px) 100vw, 640px" /></p>
<p><img class="aligncenter wp-image-60866" src="http://blog.octo.com/wp-content/uploads/2016/03/hosts.png" alt="rancher-hosts" width="640" height="312" srcset="http://blog.octo.com/wp-content/uploads/2016/03/hosts-300x146.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/hosts.png 941w" sizes="(max-width: 640px) 100vw, 640px" /></p>
<p><span style="font-weight: 400;">Rancher propose une série de “Templates” de services, dans son </span><b>catalogue</b><span style="font-weight: 400;"> : mise en place d’un ZooKeeper, d’un Hadoop + Yarn, d’une pile ELK, d’un GlusterFS, etc… Bien sûr, il est possible d’intégrer vos propres modèles à ce catalogue. En quelques commandes, votre application se déploie, selon la stratégie de base, ou personnalisée par vos soins.</span></p>
<p><span style="font-weight: 400;">Le <strong>load-balancing</strong> des conteneurs et des services, entre tous les hôtes, quels qu’ils soient, est intégré dans Rancher. Un load-balanceur est un objet à part entière, qui s’intègre à un service. Sous le capot, c’est la solution standard du marché HAProxy qui permet cela. </span></p>
<p>On retrouve également au catalogue des <strong>services DNS externes</strong> reposant sur Amazon Route 53, CloudFlare, DNSimple ou encore PointHQ. Comme toujours, il est rendu facilement possible d’ajouter un service qui ne serait pas encore “au catalogue”.</p>
<p><span style="font-weight: 400;">La montée en niveau d’un service est facilitée par une mécanique de redirection du trafic, permettant de tester le composant modifié et ses dépendances avant de le rendre disponible à tous (“<em><strong>rolling upgrade</strong></em>”). </span></p>
<p><span style="font-weight: 400;">Diagnostiquer les bugs peut se faire depuis l’interface, où il est possible de <strong>monitorer</strong> un conteneur (CPU, RAM, I/Os et utilisation réseau), visualiser ses logs, ainsi qu’ouvrir une invite de commande. Néanmoins, si cela est accessible “par conteneur” et “par hôte”, obtenir ces informations pour un “service” ou un ensemble de conteneur n’est pas prévu au programme pour le moment.</span></p>
<p><span style="font-weight: 400;">Une <strong>stratégie de placement</strong> (affinité entre les conteneurs et les hôtes, voir <a href="http://blog.octo.com/strategie-de-placement-de-conteneurs-docker-partie-1/">notre article sur le sujet</a>) est également proposée en utilisant simplement des labels. Par exemple, un load-balancer pour notre application web sera labellisé comme suit dans notre docker-compose.yml :</span></p>

<div class="wp_codebox"><table><tr id="p608522"><td class="line_numbers"><pre>1
2
3
4
5
6
7
8
9
</pre></td><td class="code" id="p60852code2"><pre class="yml" style="font-family:monospace;">  labels:
    # Je souhaite ne me deployer que sur un hôte dont la valeur du label &quot;web_exposed&quot; est &quot;yes&quot;
    io.rancher.scheduler.affinity:host_label: web_exposed=yes
&nbsp;
    # Je ne dois jamais me déployer sur un hôte disposant déjà d’un container dont la fonction est &quot;lb&quot;
    io.rancher.scheduler.affinity:container_label_ne: function=lb
&nbsp;
    # Ma fonction à moi est &quot;lb&quot;
    function: lb</pre></td></tr></table></div>

<p><span style="font-weight: 400;"><img class="wp-image-60897 size-medium alignright" src="http://blog.octo.com/wp-content/uploads/2016/03/sans-titre-300x271.png" alt="rancher-convoy" width="300" height="271" srcset="http://blog.octo.com/wp-content/uploads/2016/03/sans-titre-300x271.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/sans-titre.png 419w" sizes="(max-width: 300px) 100vw, 300px" /></span></p>
<p>&nbsp;</p>
<p><span style="font-weight: 400;">Facteur différenciant à l’heure actuelle, la gestion du stockage. Snapshot, backup et restore des volumes persistants de Dockers sont intégrés à Rancher via </span><b>Convoy</b><span style="font-weight: 400;">, une couche d’abstraction au stockage. Le travail de mise en place de solutions comme GlusterFS ou NFS est également disponible, sous forme de services pré-configurés dans le catalogue.</span></p>
<p>Enfin, Rancher est multi-tenants : en tant que solution de CaaS, Rancher propose un mécanisme de gestion d’utilisateurs : il est possible de créer des environnements séparés (dév, test, prod…) et de brancher l’identification à un annuaire existant (Active Directory, Github ou OpenLDAP).</p>
<p>&nbsp;</p>
<p><span style="font-weight: 400;">Rancher est une solution intéressante, avant tout pour son </span><i><span style="font-weight: 400;">packaging</span></i><span style="font-weight: 400;">. Nous avons en face de nous un produit bien fini visuellement, qui propose en plus un catalogue de services à mettre en place en quelques commandes. Ce catalogue permet de déployer des solutions indispensables à ce type de plateforme, comme le <em>service discovery </em>ou le stockage distribué. La facilité de mise en place est également un plus : le ticket d&rsquo;entrée est très faible, et on peut démarrer ses tests dès le premier hôte. Des éléments restent néanmoins, à l&rsquo;heure actuelle, à améliorer ; les plus importants pour nous étant la gestion de la <a href="http://docs.rancher.com/rancher/upgrading/">montée de version de la plateforme</a>, et l&rsquo;<a href="http://docs.rancher.com/rancher/installing-rancher/installing-server/multi-nodes/">absence de haute disponibilité intégrée</a> pour votre serveur maître. Espérons que la version 1.0, <a href="https://github.com/rancher/rancher/milestones">prévue pour fin mars</a>, saura adresser ces points !</span></p>
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/" rel="bookmark" title="Docker en production : la bataille sanglante des orchestrateurs de conteneurs">Docker en production : la bataille sanglante des orchestrateurs de conteneurs </a></li>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/nous-etions-a-la-kubecon-europe/" rel="bookmark" title="Nous étions à la KubeCon Europe (1/2)">Nous étions à la KubeCon Europe (1/2) </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/la-ruee-vers-le-conteneur/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Bonne nouvelle : L’Infra As Code c’est du code !</title>
		<link>http://blog.octo.com/bonne-nouvelle-linfra-as-code-cest-du-code/</link>
		<comments>http://blog.octo.com/bonne-nouvelle-linfra-as-code-cest-du-code/#respond</comments>
		<pubDate>Thu, 24 Mar 2016 11:31:00 +0000</pubDate>
		<dc:creator><![CDATA[Mathieu Herbert]]></dc:creator>
				<category><![CDATA[Infrastructure et opérations]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=60940</guid>
		<description><![CDATA[La notion d&#8217;Infra As Code consiste à voir l’infrastructure comme un asset logiciel classique. Bonne nouvelle, on va pouvoir reprendre des pratiques liées au code de la Programmation Orientée Objet. Dans cet article nous allons nous intéresser à une de ces pratiques : l&#8217;abstraction. Il s’agit de séparer la mise en oeuvre technique bas niveau de son utilisation [&#8230;]<div class='yarpp-related-rss yarpp-related-none'>
</div>
]]></description>
				<content:encoded><![CDATA[<p>La notion d&rsquo;Infra As Code consiste à voir l’infrastructure comme un asset logiciel classique. Bonne nouvelle, on va pouvoir reprendre des pratiques liées au code de la Programmation Orientée Objet.</p>
<p><span style="font-weight: 400;">Dans cet article nous allons nous intéresser à une de ces pratiques : </span><span style="font-weight: 400;"><a href="http://infolab.stanford.edu/~burback/watersluice/node147.html" target="_blank">l&rsquo;abstraction</a></span><span style="font-weight: 400;">. </span><span style="font-weight: 400;">Il s’agit de séparer la mise en oeuvre technique bas niveau de son utilisation faite à plus haut niveau</span><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">Votre objectif en construisant des abstractions doit être le même : masquer la complexité pour être le plus largement et le plus facilement utilisé ! Tout l’art réside dans le bon dosage : un composant sans complexité ne nécessite pas d’abstraction. </span></p>
<p><span style="font-weight: 400;">Adopter cet état d’esprit aide plus que n’importe quelle formation théorique pour construire des abstractions efficaces.</span></p>
<p><span id="more-60940"></span></p>
<h2><span style="font-weight: 400;">Pourquoi investir dans des abstractions ?</span></h2>
<h3><span style="font-weight: 400;">Assurer le développement des parties complexes par les experts</span></h3>
<p><span style="font-weight: 400;">Personne n’est expert en tout, mais il existe toujours au moins un référent par technologie dans chaque entreprise. </span></p>
<p><span style="font-weight: 400;">Ces référents ne se multiplient pas et ne peuvent participer à tous les projets (Brent dans <a href="http://www.amazon.com/The-Phoenix-Project-Helping-Business/dp/0988262592" target="_blank">The Phoenix Project</a></span><span style="font-weight: 400;">) : nous sommes convaincus que ces personnes peuvent faciliter l’accès à leur expertise en développant des couches d’abstraction adaptées au contexte de l’entreprise.</span></p>
<h3><span style="font-weight: 400;">Réutiliser les implémentations pour différents projets </span></h3>
<p><span style="font-weight: 400;">L’accès et l&rsquo;adhésion à ces abstractions sont les clés de la réutilisabilité. </span><span style="font-weight: 400;">Une belle abstraction qui n’a jamais été utilisée car incomprise ou inadaptée a une valeur métier proche du néant. Et ce, bien que l’abstraction en elle-même soit élégante d’un point de vue expertise technique et de code. </span><span style="font-weight: 400;">Ce que l’on décrit ici peut se transposer à l’utilisation de librairies dans le monde Open Source.</span></p>
<p><span style="font-weight: 400;">Pourquoi <a href="https://rubygems.org/gems/rest-client" target="_blank">rest-client</a></span><span style="font-weight: 400;"> ou <a href="https://rubygems.org/gems/httparty" target="_blank">httparty</a></span><span style="font-weight: 400;"> dans le monde Ruby sont plus souvent utilisés pour appeler des services Rest que <a href="http://ruby-doc.org/stdlib-2.3.0/libdoc/net/http/rdoc/Net/HTTP.html#class-Net::HTTP-label-GET" target="_blank">Net::HTTP</a></span><span style="font-weight: 400;"> pourtant natif ? </span><span style="font-weight: 400;">Au-delà d’être de bonnes abstractions, celles-ci sont populaires et bien documentées : nous avons accès au code source pour debugger d&rsquo;éventuels comportements étranges, et il est possible de les enrichir ou de corriger des bugs à travers des <a href="https://help.github.com/articles/using-pull-requests/" target="_blank">Pull Requests</a></span><span style="font-weight: 400;">.</span></p>
<h2><span style="font-weight: 400;">Les différents niveaux d’abstraction</span></h2>
<p><span style="font-weight: 400;">Dans l’environnement des outils de gestion de configuration, on retrouve . 2 niveaux d’abstractions de base : Ressource et Module, ce dernier peut être affiné en deux sous parties : le module expert, le module métier.</span></p>
<h3><span style="font-weight: 400;">La ressource : l’unité de base</span></h3>
<p><span style="font-weight: 400;">La ressource est le niveau d’abstraction le plus bas, c’est celle qui est le plus proche de l’action réellement effectuée sur le serveur cible. On peut la comparer aux fonctions de base d’un langage.</span></p>
<p><span style="font-weight: 400;">Le pattern Ressource nous permet de passer d’une logique d’action à une logique d’état désiré. C’est l’application de ce pattern qui nous permet d’assurer <a href="http://tylerturk.com/testing-ansible-idempotency/" target="_blank">l’idempotence</a></span><span style="font-weight: 400;"> de notre code assez facilement. </span></p>
<p><span style="font-weight: 400;">Par exemple, nous souhaitons rajouter une entrée dans le fichier </span><i><span style="font-weight: 400;">/etc/hosts </span></i><span style="font-weight: 400;">de notre serveur.</span></p>
<p><span style="font-weight: 400;">En Shell, pour ajouter une entrée nous pouvons faire :</span></p>
<blockquote>
<pre><span style="font-weight: 400;">echo "127.0.0.1 localhost" &gt;&gt; /etc/hosts</span></pre>
</blockquote>
<p><span style="font-weight: 400;">Si nous voulons rendre cette action idempotente, on peut essayer :</span></p>
<blockquote>
<pre><span style="font-weight: 400;">if (!grep -q 127.0.0.1 /etc/hosts); then echo "127.0.0.1 localhost" &gt;&gt; /etc/hosts; fi</span></pre>
</blockquote>
<p><span style="font-weight: 400;">Et en puppet :</span></p>
<blockquote>
<pre><span style="font-weight: 400;"> host { 'localhost':
</span><span style="font-weight: 400;">    ip =&gt; '127.0.0.1',
</span><span style="font-weight: 400;"> }</span></pre>
</blockquote>
<p><span style="font-weight: 400;">Quel type de code souhaitez vous maintenir?</span></p>
<p><img class="aligncenter size-full wp-image-60941" src="http://blog.octo.com/wp-content/uploads/2016/03/idempot.png" alt="shellpuppethost" width="602" height="323" srcset="http://blog.octo.com/wp-content/uploads/2016/03/idempot-300x161.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/idempot.png 602w" sizes="(max-width: 602px) 100vw, 602px" /></p>
<p><span style="font-weight: 400;">Lorsque l’on fait du Shell il est nécessaire de regarder le delta par rapport à la cible et en fonction de cela, nous effectuons la transition. La commande Shell présentée, semble gérer le delta correctement, mais on peut trouver des cas où l’état préalable n’est pas géré (<em>127.0.0.1 </em>est présent mais n&rsquo;est pas associé à <em>localhost</em>). Les gérer vaut-il la peine de complexifier le code ?</span></p>
<p><span style="font-weight: 400;">Dans le cas de Puppet, le pattern Ressource nous permet de spécifier directement l’état cible et c’est l’outil qui nous masque la transition.</span></p>
<p><span style="font-weight: 400;">L’usage du pattern Ressource présente l&rsquo;intérêt qu’il s’intéresse à l’état désiré en masquant la constellation d’états de départ potentiellement infini.</span></p>
<h3><span style="font-weight: 400;">Module expert : masquer la complexité d’une brique technique</span></h3>
<p><span style="font-weight: 400;">L’écriture de ce module nécessite une connaissance intime de la brique manipulée. Mais elle nécessite également une bonne connaissance de l’outil de gestion de configuration afin de l’utiliser au mieux et de ne pas enchaîner des commandes Shell bas niveau.</span></p>
<p><span style="font-weight: 400;">Celui-ci connaît et gère par exemple : la syntaxe et l’emplacement des fichiers de configuration, le processus de déploiement, la validité des versions, les différents comportements entre versions et OS, le chemin vers les binaires&#8230;</span></p>
<p><span style="font-weight: 400;">De plus, il expose une interface d’entrée simplifiée : on peut notamment y retrouver des flags de <a href="http://blog.octo.com/feature-flipping/" target="_blank">feature flipping</a></span><span style="font-weight: 400;">.</span></p>
<p>&nbsp;</p>
<h3><span style="font-weight: 400;">Module métier : intégrer nos besoins spécifiques</span></h3>
<p><span style="font-weight: 400;">Il assure la corrélation entre le besoins besoins spécifiques au projet/contexte métier et l’appel aux modules experts. Nous allons donc retrouver des appels à de multiples modules experts, mais aussi la définition de variables métiers ou connexes à l’organisation. </span></p>
<p><span style="font-weight: 400;">Il faut faire attention à ce que l’on mets derrière le mot &laquo;&nbsp;métier&nbsp;&raquo; : on ne parle pas ici de transposer des règles métier liée à l’entreprise dans le code d’infrastructure. On parle de toutes les pratiques internes liées à l’usage de l’infrastructure : un module métier peut être un module qui exploite un module expert tomcat et un module expert logstash pour en faire un tomcat configuré dans le contexte de production avec la tuyauterie de collecte de log. Par nature, ce type de module est spécifique au contexte de l&rsquo;entreprise. </span></p>
<p><span style="font-weight: 400;">Ces modules métier ne connaissent ni l’emplacement des fichiers de configuration, ni aucun composant technique précis. Cela lui est abstrait par le module expert.</span></p>
<p><span style="font-weight: 400;">Si nous voulons installer un MySQL avec Puppet, nous utiliserons un module expert (ici, issu de la communauté) puis dans le module métier nous le référencerons :</span></p>
<blockquote>
<pre>class<span style="font-weight: 400;"> { </span><span style="font-weight: 400;">'::mysql::server'</span><span style="font-weight: 400;">:</span>
 <span style="font-weight: 400;">  </span><span style="font-weight: 400;">root_password</span><span style="font-weight: 400;">           =&gt; </span><span style="font-weight: 400;">'strongpassword'</span><span style="font-weight: 400;">,</span>
 <span style="font-weight: 400;">  </span><span style="font-weight: 400;">remove_default_accounts</span><span style="font-weight: 400;"> =&gt; </span><span style="font-weight: 400;">true,</span>
 <span style="font-weight: 400;">}</span></pre>
</blockquote>
<p><span style="font-weight: 400;">Nous indiquons au module expert un nouveau mot de passe root et la suppression des comptes par défaut. À lui de savoir installer MySQL.</span></p>
<p><span style="font-weight: 400;">Il est écrit par un développeur connaissant les spécificités métiers (organisation, utilisation du produit, manière d’exploiter&#8230;). Il n’a pas besoin d’être expert sur le produit installé mais doit comprendre l’interface offerte par le module expert.</span></p>
<p>&nbsp;</p>
<h2><span style="font-weight: 400;">Correspondance des concepts</span></h2>
<p><span style="font-weight: 400;">Ces trois niveaux peuvent se transposer dans les différents outils de management de configuration mais aussi avec la Programmation Orientée Objet.</span></p>
<p>&nbsp;</p>
<table>
<tbody>
<tr>
<td></td>
<td><span style="font-weight: 400;">Programmation Objet</span></td>
<td><span style="font-weight: 400;">Shell</span></td>
<td><span style="font-weight: 400;">Puppet</span></td>
<td><span style="font-weight: 400;">Ansible</span></td>
</tr>
<tr>
<td><span style="font-weight: 400;">Ressource</span></td>
<td><span style="font-weight: 400;">Fonction de base d’un langage</span></td>
<td><span style="font-weight: 400;">Fonction complexe</span></td>
<td><span style="font-weight: 400;">Ressource</span></td>
<td><span style="font-weight: 400;">Module</span></td>
</tr>
<tr>
<td><span style="font-weight: 400;">Module expert</span></td>
<td><span style="font-weight: 400;">Interface</span></td>
<td><span style="font-weight: 400;">Fonction qui appelle des fonctions “Ressource”</span></td>
<td><span style="font-weight: 400;">Module (principalement issu de la communauté)</span></td>
<td><span style="font-weight: 400;">Role (principalement issu de la communauté)</span></td>
</tr>
<tr>
<td><span style="font-weight: 400;">Module métier</span></td>
<td><span style="font-weight: 400;">Consommation de l’interface</span></td>
<td><span style="font-weight: 400;">Script</span></td>
<td><span style="font-weight: 400;">Profile (privé)</span></td>
<td><span style="font-weight: 400;">Role/Playbook (privé)</span></td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<h2><span style="font-weight: 400;">Wrap up</span></h2>
<p><span style="font-weight: 400;">L’approche ne doit pas être confondue avec la simple automatisation de l’existant. La construction de ces abstractions sera plus complexe avec certains outils graphiques, langages propriétaires simplistes et autres outils orientés “automatisation de l’existant”.</span></p>
<p><span style="font-weight: 400;">Ces outils limités ne permettent pas de construire des abstractions, de réaliser des diffs, de faire du dry-run, ou de travailler de manière collaborative. Ils ne sont pas dans la mouvance Infra As Code mais dans une logique d’automatisation de processus ad-hoc.</span></p>
<p><span style="font-weight: 400;">Les outils dans cette mouvance d’Infra As Code nécessitent de refaire tout ce qui à été développé dans le passé et de revoir les processus d’automatisation souvent obsolètes et pauvres. Cela prend du temps et demande un investissement initial mais c’est nécessaire !</span></p>
<p><span style="font-weight: 400;">Avec cette approche nous serons en mesure de reprendre bien d’autres patterns éprouvés issus du monde logiciel : refactoring, clean code, usines de développements, tests automatisés, pratiques organisationnelles liées à l’agile et au software craftsmanship … Ils permettent de garantir la maintenabilité et la qualité du code.  L’infra As Code va bien au-delà d’un “yum install” dans un script !</span></p>
<div class='yarpp-related-rss yarpp-related-none'>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/bonne-nouvelle-linfra-as-code-cest-du-code/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Angular 2 : Savoir composer avec les composants</title>
		<link>http://blog.octo.com/angular-2-savoir-composer-avec-les-composants/</link>
		<comments>http://blog.octo.com/angular-2-savoir-composer-avec-les-composants/#respond</comments>
		<pubDate>Mon, 14 Mar 2016 08:00:50 +0000</pubDate>
		<dc:creator><![CDATA[Franck Libam Moutngui]]></dc:creator>
				<category><![CDATA[Archi & techno]]></category>
		<category><![CDATA[AngularJS]]></category>
		<category><![CDATA[composants]]></category>
		<category><![CDATA[Front-end]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=60481</guid>
		<description><![CDATA[Peu importe notre préférence en matière de framework front end JavaScript, AngularJS a modernisé notre façon de concevoir et réaliser des applications web riches, stables et performantes. Convaincus par AngularJS, nous suivons de près le projet Angular 2, qui s&#8217;annonce radicalement différent de son prédécesseur. En effet, le framework a été entièrement réécrit. Il se [&#8230;]<div class='yarpp-related-rss yarpp-related-none'>
</div>
]]></description>
				<content:encoded><![CDATA[<p>Peu importe notre préférence en matière de framework front end JavaScript, AngularJS a modernisé notre façon de concevoir et réaliser des applications web riches, stables et performantes.</p>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/angular-2-savoir-composer-avec-les-composants/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Docker en production : la bataille sanglante des orchestrateurs de conteneurs</title>
		<link>http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/</link>
		<comments>http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/#comments</comments>
		<pubDate>Thu, 10 Mar 2016 08:00:04 +0000</pubDate>
		<dc:creator><![CDATA[Édouard Devouge]]></dc:creator>
				<category><![CDATA[Infrastructure et opérations]]></category>
		<category><![CDATA[Cluster]]></category>
		<category><![CDATA[container]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Google]]></category>
		<category><![CDATA[Kubernetes]]></category>
		<category><![CDATA[OpenShift]]></category>
		<category><![CDATA[Orchestrateur de conteneur]]></category>
		<category><![CDATA[Production]]></category>
		<category><![CDATA[swarm]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=60451</guid>
		<description><![CDATA[1. Vous êtes perdus&#8230; Cela fait maintenant plusieurs mois, voire plus d’un an que vous êtes intellectuellement convaincus de l’approche de Docker et des conteneurs applicatifs : portabilité, universalité, volatilité. La promesse est tenue et vous avez déjà remporté quelques victoires en développant localement et sur quelques environnements d’intégration, bravo. C’est à ce moment que [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/strategie-de-placement-de-conteneurs-docker-partie-1/" rel="bookmark" title="Stratégies de placement de conteneurs Docker (partie 1)">Stratégies de placement de conteneurs Docker (partie 1) </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<h1>1. Vous êtes perdus&#8230;</h1>
<p style="text-align: justify;">Cela fait maintenant plusieurs mois, voire plus d’un an que vous êtes intellectuellement convaincus de l’approche de Docker et des conteneurs applicatifs : portabilité, universalité, volatilité.</p>
<p style="text-align: justify;">La promesse est tenue et vous avez déjà remporté quelques victoires en développant localement et sur quelques environnements d’intégration, bravo.</p>
<p style="text-align: justify;">C’est à ce moment que la question du passage à l’échelle se pose et d’un coup, le signal se brouille. Vous êtes soudainement noyés sous un déluge de noms et d’acronymes barbares. Et surtout, vous sentez comme une odeur de poudre. Il y a du rififi au pays des moteurs de clustering Docker. Rien qu’à l’évocation de ces noms, « Docker Swarm, Kubernetes, Rancher, Mesos, Marathon, Titus, Nomad, Fleet ou encore Deis », vous vous sentez fébrile, en retard sur le dernier framework hype et peut-être en train de passer à côté de LA solution ultime.</p>
<table style="text-align: center;" width="100%">
<tbody>
<tr>
<td>
<p style="text-align: left;"><strong>« Écoute, on t&rsquo;connaît pas, mais laisse nous t&rsquo;dire que tu t&rsquo;prépares des nuits blanches&#8230; Des migraines&#8230; Des &laquo;&nbsp;nervous breakdown&nbsp;&raquo;, comme on dit de nos jours. »</strong></p>
<p style="text-align: right;">Michel Audiard (Les Tontons flingueurs – 1963)</p>
</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p style="text-align: justify;">Nous vous proposons ici quelques éléments pour y voir un peu plus clair dans l’opposition Kubernetes/Swarm.</p>
<p><span id="more-60451"></span></p>
<p>Commençons par regrouper tout ces produits comme étant (au moins sur une partie de leur périmètre) des CaaS, pour <strong>C</strong>ontainer <strong>a</strong>s <strong>a</strong> <strong>S</strong>ervice. Le conteneur Docker est alors l’unité de déploiement d’une offre de service plus vaste comprenant la gestion du cycle de vie des conteneurs, leur orchestration, leur placement, leurs interconnexions…</p>
<h1>2. Un état de guerre ouverte</h1>
<p style="text-align: justify;">Si c’est autour de Mesos, Kubernetes et Docker Swarm que se concentrent les attentions, c’est bien entre Google (géniteur de Kubernetes) et Docker Inc que s’entretiennent les plus fortes tensions.</p>
<p style="text-align: justify;">L’enjeu de cette guerre froide est sans appel : celui qui remportera la bataille des orchestrateurs dominera le monde.</p>
<table style="text-align: center;" width="100%">
<tbody>
<tr>
<td>
<p style="text-align: left;"><strong>« Mais moi les dingues, j&rsquo;les soigne, j&rsquo;m&rsquo;en vais lui faire une ordonnance, et une sévère, j’vais lui montrer qui c’est Raoul. Aux quatre coins d&rsquo;Paris qu&rsquo;on va l’retrouver, éparpillé par petits bouts façon puzzle&#8230; Moi, quand on m’en fait trop j&rsquo;correctionne plus, j&rsquo;dynamite, j&rsquo;disperse, et j&rsquo;ventile. »</strong></p>
<p style="text-align: right;">Michel Audiard (Les Tontons flingueurs – 1963)</p>
</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p style="text-align: justify;">Dans la bataille, les deux belligérants engagent toutes leurs forces de frappe pour montrer leur supériorité : animation des communautés les plus grandes, multiplication des partenariats, création de standards, de <a href="https://www.opencontainers.org/">fondations</a> et lobbies, participation aux conférences les plus en vogues, saturation de l’actualité geek avec des annonces permanentes, billets de blog et tweets assassins, refus de pull requests, distribution de tee-shirts à baleine bleue et autres concours du plus grand nombre de stickers sur les MacBooks des développeurs.</p>
<p style="text-align: justify;"><img class="aligncenter wp-image-60457" src="http://blog.octo.com/wp-content/uploads/2016/03/rocket-1024x416.png" alt="Kubernetes versus Swarm" width="798" height="324" srcset="http://blog.octo.com/wp-content/uploads/2016/03/rocket-300x122.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/rocket-1024x416.png 1024w, http://blog.octo.com/wp-content/uploads/2016/03/rocket.png 1384w" sizes="(max-width: 798px) 100vw, 798px" /></p>
<p style="text-align: justify;">Jusque là nous étions restés dans une guerre propre. C’était sans compter sur la “<a href="http://www.wired.com/2015/05/google-backs-alternative-docker-cloud-computing-s-next-big-idea/">Rocket</a>” que Google et CoreOS ont lancé pour essayer de torpiller le porte-conteneurs Docker. Cette initiative avait pour vocation de proposer un standard de conteneurisation alternatif en dehors du périmètre d&rsquo;influence de Docker Inc.</p>
<table style="text-align: center;" width="100%">
<tbody>
<tr>
<td>
<p style="text-align: left;"><strong>« Le flinguer comme ça de sang froid, sans être tout à fait de l’assassinat, y&rsquo;aurait quand même comme un cousinage ! »</strong></p>
<p style="text-align: right;">Michel Audiard (Ne nous fâchons pas – 1966)</p>
</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p style="text-align: justify;">Docker Inc arrive sur le marché de l’orchestration avec une légitimité toute naturelle : ce sont eux qui ont proposé le concept disruptif et crédible du conteneur. Cette vision est en ligne avec les paradigmes les plus swags du moment (DevOps, intégration et déploiement en continu, cattle vs. pet, rebuild vs upgrade) et a connu, à juste titre, une explosion de popularité auprès des développeurs <em>in</em>. Il serait donc naturel de croire que Docker Inc va avoir une approche tout aussi efficace pour gérer tout un écosystème de conteneurs jusqu’à la prod. La stack <a href="https://www.docker.com/products/docker-universal-control-plane">UCP</a> (Universal Control Plane) se fait clairement l’écho de cette ambition.</p>
<p style="text-align: justify;">Google d’un autre côté a habilement saisi au vol la manne céleste du conteneur et peut se targuer d’avoir l’expérience de la gestion de centaines de milliers de ces petites boites en production (sur une technologie interne, antérieure à Docker : <a href="https://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/43438.pdf">Borg</a>), et ce depuis plus de 10 ans. On peut être enclin à les croire quand ils annoncent que Kubernetes est en fait un concentré de ce savoir-faire, expressément réécrit pour Docker.</p>
<h1>3. Notre position</h1>
<p style="text-align: justify;">Difficile de prédire l’avenir dans notre métier, puisque les roadmaps annoncées sont à prendre avec des pincettes. Pourtant, notre expérience accumulée depuis plusieurs mois nous permet de faire aujourd’hui une préconisation assez tranchée : si vous devez vous lancer aujourd&rsquo;hui, partez sur Kubernetes.</p>
<p style="text-align: justify;">C’est à notre sens la stack technologique la plus mature et prometteuse pour un projet de CaaS en production.</p>
<p style="text-align: justify;"><img class="aligncenter wp-image-60458" src="http://blog.octo.com/wp-content/uploads/2016/03/octo-tranchee-1024x269.png" alt="OCTO-Tranchée" width="590" height="155" srcset="http://blog.octo.com/wp-content/uploads/2016/03/octo-tranchee-300x79.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/octo-tranchee-1024x269.png 1024w, http://blog.octo.com/wp-content/uploads/2016/03/octo-tranchee.png 1255w" sizes="(max-width: 590px) 100vw, 590px" /></p>
<h2>3.1 Couverture fonctionnelle : Swarm <em>versus</em> Kubernetes</h2>
<p style="text-align: justify;">Kubernetes offre les fonctions natives que l’on peut être en droit d’attendre d’un gestionnaire de clusters en production. Citons en particulier le <a href="http://whatis.techtarget.com/definition/self-healing">self-healing</a>, un orchestrateur capable de réagir à des changements de topologie des nœuds, notamment le crash, ce qui n’est pas (encore) le cas dans Swarm (la version 1.1 de Swarm sortie en même temps que Docker 1.10 le propose uniquement en expérimental).</p>
<p style="text-align: justify;">Citons également la <a href="http://kubernetes.io/v1.0/docs/user-guide/secrets.html">gestion native des secrets</a>, des comptes de services, des <a href="http://kubernetes.io/v1.1/docs/user-guide/namespaces.html">namespaces</a>, des autorisations, le load-balancing, l’<a href="http://kubernetes.io/v1.1/docs/user-guide/horizontal-pod-autoscaler.html">autoscaling</a> de conteneurs (en version ß), bref nous voilà en face d’une solution presque complète.</p>
<p style="text-align: justify;"><a href="http://blog.octo.com/wp-content/uploads/2016/03/octo-swarm-kubernetes-features-comparison.png" rel="attachment wp-att-60459"><img class="aligncenter wp-image-60459" src="http://blog.octo.com/wp-content/uploads/2016/03/octo-swarm-kubernetes-features-comparison-1024x453.png" alt="OCTO-Swarm-Kubernetes-features-comparison" width="775" height="343" srcset="http://blog.octo.com/wp-content/uploads/2016/03/octo-swarm-kubernetes-features-comparison-300x133.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/octo-swarm-kubernetes-features-comparison-1024x453.png 1024w, http://blog.octo.com/wp-content/uploads/2016/03/octo-swarm-kubernetes-features-comparison.png 1507w" sizes="(max-width: 775px) 100vw, 775px" /></a></p>
<h2>3.2 Sur les épaules d’un Géant</h2>
<p style="text-align: justify;">Pour mesurer tout le potentiel de Kubernetes, c’est du côté de RedHat qu’il faut porter le regard, en particulier sur OpenShift Origin.</p>
<p style="text-align: justify;">L’éditeur a pris clairement position dans la bataille au côté de Google et CoreOS en prenant une certaine distance vis-à-vis de <a href="https://lwn.net/Articles/676831/">Docker Inc</a> qui rend coup pour coup.</p>
<p style="text-align: justify;">En faisant le pari de bâtir sa nouvelle mouture d’OpenShift v3 sur Kubernetes, RedHat propose un trait d’union entre le CaaS et le <a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/">PaaS</a>. On se trouve donc en face d’une solution hybride, capable de proposer simultanément les 2 étages de la fusée :</p>
<ul>
<li style="text-align: justify;">Le PaaS : avec sa double capacité à :
<ul>
<li>accepter directement du code source en entrée (PHP, Node, Python, Ruby, Java…) et à prendre en charge ensuite le build et le déploiement</li>
<li>instancier des topologies de conteneurs rassemblés sous forme de blueprints (ou templates)</li>
</ul>
</li>
<li style="text-align: justify;">Le CaaS : la gestion très fine de l’assemblage de tous types de conteneurs Docker dans des topologies 100% personnalisables, en dehors de tout cadre rigide</li>
</ul>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1-150x150.png" alt="openshift" width="150" height="150" class="aligncenter size-thumbnail wp-image-60471" srcset="http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1-300x300.png 300w, http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1-128x128.png 128w, http://blog.octo.com/wp-content/uploads/2016/03/1024px-openshift-logotype-svg-1.png 1024w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<h2>3.3 Des philosophies aux antipodes</h2>
<p style="text-align: justify;">C’est principalement dans l’approche et les paradigmes de Kubernetes que l’on mesure l’avance par rapport à Swarm.</p>
<h3><strong>3.3.1 Kubernetes : la production en ligne de mire</strong></h3>
<p style="text-align: justify;">Google a directement pensé Kubernetes (ou k8s pour les intimes) pour répondre à des problématiques de production, là où Swarm et Docker ajouteront progressivement des fonctions pourtant majeures :</p>
<ul style="text-align: justify;">
<li>Approche basée sur des <em>namespaces</em> isolant les ressources entre elles</li>
<li>Authentification via OpenIDConnect, certificats clients, …</li>
<li>Développement d’outils (sous forme de conteneurs) de collecte de métriques des conteneurs (CAdvisor, Heapster), de DNS dynamique, &#8230;</li>
</ul>
<p style="text-align: justify;">Docker Swarm et Kubernetes s’opposent également dans leur philosophie :</p>
<ul style="text-align: justify;">
<li><strong>Simple mais limité </strong>: Swarm a fait le choix de rendre transparente l’utilisation des conteneurs en local ou sur un cluster distant. Cette promesse est très séduisante mais sous prétexte de masquer la complexité au développeur, elle devient limitante dans la modélisation des contraintes d’exploitabilité.</li>
<li><strong>Puissant mais complexe</strong> : Kubernetes assume une modélisation riche (crédible jusqu’en production), même si cela est moins confortable pour les développeurs.</li>
</ul>
<p style="text-align: justify;">Installer une stack Kubernetes complète sur son poste de développement est peut-être trop fastidieux pour un développeur, qui, finalement, pourrait se satisfaire des fonctionnalités de Swarm.</p>
<h3>3.3.2 Kubernetes : une modélisation plus aboutie</h3>
<p style="text-align: justify;">Kubernetes propose un modèle de description des applications autour de 4 concepts majeurs : la mécanique de <a href="http://kubernetes.io/v1.1/docs/user-guide/labels.html">Labels/Selectors</a>, les <a href="http://kubernetes.io/v1.1/docs/user-guide/services.html">Services</a>, les <a href="http://kubernetes.io/v1.1/docs/user-guide/pods.html">Pods</a> et les <a href="http://kubernetes.io/v1.1/docs/user-guide/replication-controller.html">ReplicationControllers</a>. À partir d’idées unitairement simples, il devient possible de gérer facilement :</p>
<ul style="text-align: justify;">
<li>des pools de conteneurs d’un rôle identique</li>
<li>leur load-balancing</li>
<li>leur rolling-update</li>
<li>le tout, avec une capacité naturelle à s’adapter aux aléas (pannes, plantages de conteneurs)</li>
</ul>
<p style="text-align: justify;">Ces notions sont moins simples à appréhender que celles de Docker Compose mais montrent également bien plus de potentiel et de puissance. Nous pensons que plus nous nous rapprochons des vraies contraintes de la production plus les capacités offertes par ces concepts deviennent nécessaires (scalabilité, résilience et sécurité).</p>
<table style="text-align: center;" width="100%">
<tbody>
<tr>
<td>
<p style="text-align: left;"><strong>«- Faut reconnaître&#8230; C&rsquo;est du brutal.</strong></p>
<p style="text-align: left;"><strong>&#8211; Vous avez raison, c&rsquo;est curieux hein</strong></p>
<p style="text-align: left;"><strong>&#8211; J&rsquo;ai connu une polonaise qui en prenait au petit-déjeuner.»</strong></p>
<p style="text-align: right;">Michel Audiard (Les Tontons flingueurs – 1963)</p>
</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<h2>3.4 Le poids de l’Histoire (oui, déjà)</h2>
<p style="text-align: justify;">Docker a fait un choix discutable en misant sur Fig (qui deviendra plus tard Docker Compose). Ce choix tactique est à ce jour un caillou dans la chaussure de Docker Inc. Il manque certains concepts dans le format v1 de Docker Compose et l’arrivée du format 2.0 a été un passage obligé pour apporter plus de subtilité au prix d’une migration laborieuse. Le mot-clé <a href="https://docs.docker.com/compose/compose-file/#service-configuration-reference">services:</a> en est la matérialisation. Mais la route est encore longue et s’annonce périlleuse. À ce jour la notion de service de Compose n’apporte pas les fonctions de load-balancing des services natives à Kubernetes. On regrette également qu’il ne soit pas possible de préciser le nombre absolu de copies des conteneurs à faire tourner dans Swarm&#8230;</p>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/03/compose-150x150.png" alt="Compose" width="150" height="150" class="aligncenter size-thumbnail wp-image-60473" srcset="http://blog.octo.com/wp-content/uploads/2016/03/compose-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/03/compose-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/03/compose-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/03/compose-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/03/compose-128x128.png 128w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<h2>3.5 Là où notre avis n’est pas (encore) tranché</h2>
<p style="text-align: justify;">Il serait naïf de penser que tout est parfait dans le monde merveilleux de Kubernetes et que Swarm n’est qu’une pale tentative vouée à l’échec. Dans la réalité, les choses sont bien entendu plus nuancées.</p>
<p style="text-align: justify;">Côté poste de développement, nous l’avons évoqué, faire du Docker Machine + Docker Engine + Docker Compose est plus naturel à utiliser que Kubernetes. <a href="https://github.com/skippbox/kmachine">k</a><a href="https://github.com/skippbox/kmachine">machine</a> vient en partie réduire la complexité de déploiement de k8s en montant une instance locale mono-nœud à moindre frais. Cela ne dispense cependant pas de connaître et de manipuler les concepts de Kubernetes.</p>
<p style="text-align: justify;">D’un autre côté, penser qu’un fichier Docker Compose utilisé en développement va directement pouvoir passer en production est illusoire. L’utilisation de networks de type <a href="https://docs.docker.com/engine/userguide/networking/dockernetworks/#an-overlay-network">overlay</a>, de volumes externes sont autant de subtilités qui ne sont pas <em>a priori</em> un sujet de préoccupation en phase de développement et qu’il faudra pourtant bien adresser même dans le monde de Docker Inc.</p>
<p style="text-align: justify;">L’approche multi-réseaux applicatifs est un point fort de Swarm/Docker, et Kubernetes ne peut pas rivaliser aujourd’hui avec ce niveau de segmentation. Nous sommes à la KubeCon 2016 avec beaucoup d’attentes sur ce sujet précis.</p>
<p style="text-align: justify;">Côté stockage, l’approche à base de <a href="http://kubernetes.io/v1.1/docs/user-guide/persistent-volumes.html">PersistentVolume / PersistentVolumeClaim</a> de Kubernetes ne nous a pas totalement séduits. Là aussi, le modèle n’est pas encore abouti. Certaines promesses de la future version 1.2 de Kubernetes pourraient améliorer les choses, mais gardons-nous de nous réjouir prématurément.</p>
<p style="text-align: justify;">Il reste des domaines sur lesquels nos belligérants se rejoignent tristement et doivent faire preuve d’une nette amélioration : la gestion des logs, la supervision et l’administration du cluster. Les solutions proposées sont aujourd’hui encore bien lourdes à mettre en œuvre et à intégrer au reste du SI.</p>
<h1>4. Épilogue : Empires et Fondations</h1>
<p style="text-align: justify;">Comme dans la plupart des projets OpenSource, la sélection naturelle va faire son œuvre, mais elle laisse pour l’instant un goût très amer.</p>
<table style="text-align: center;" width="100%">
<tbody>
<tr>
<td>
<p style="text-align: left;"><strong>« Patricia, mon petit, je ne voudrais pas te paraître vieux jeux et encore moins grossier&#8230; L&rsquo;homme de la pampa parfois rude, reste toujours courtois&#8230; Mais la vérité m&rsquo;oblige à te le dire : Ton Antoine commence à me les briser menu ! »</strong></p>
<p style="text-align: right;">Michel Audiard (Les Tontons flingueurs – 1963)</p>
</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p style="text-align: justify;">Bien que la guerre soit loin d’être terminée, notre recommandation pour Kubernetes ne fait pas de doute.</p>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-150x150.png" alt="Kubernetes" width="150" height="150" class="aligncenter size-thumbnail wp-image-60254" srcset="http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-300x300.png 300w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-1024x1024.png 1024w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-128x128.png 128w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p style="text-align: justify;">Swarm manque actuellement de fonctions majeures pour pouvoir prétendre à rattraper son retard : un orchestrateur complet, une gestion des pools de conteneurs, le load-balancing natif, le multi-tenant&#8230;</p>
<p style="text-align: justify;">De son côté Kubernetes a encore du chemin à parcourir pour tenir pleinement sa promesse : le cloisonnement réseau et la gestion des stockages persistants sont à améliorer profondément.</p>
<p style="text-align: justify;">En définitive, nous nous demandons si ce conflit des orchestrateurs ne va pas avoir un impact collatéral sur le standard des conteneurs lui-même, et de fait pénaliser les utilisateurs. Que va-t-il advenir du rêve d’un standard partagé dans cette belle fondation qu’est l’<a href="https://www.opencontainers.org/">Open Container Initiative</a> ?</p>
<blockquote><p>Pendant ce temps, d’autres projets sont également dans nos radars et font l’objet d’une surveillance constante : <a href="http://rancher.com/rancher/">Rancher</a> (pour sa simplicité et sa vision cross-cloud) et <a href="https://www.nomadproject.io/">Nomad</a> d’HashiCorp (pour son paradigme <a href="http://blog.octo.com/strategie-de-placement-de-conteneurs-docker-partie-1/">Datacenter Aware</a>).</p></blockquote>
<p><em>Pour aller plus loin, <a href="http://www.octo.academy/fr/f/48-concevoir-un-paas-open-source-avec-docker">notre formation Docker</a> aborde une grande partie des ces sujets.</em></p>
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
<li><a href="http://blog.octo.com/openshift-3-le-paas-prive-avec-docker/" rel="bookmark" title="OpenShift 3 : le PaaS privé avec Docker">OpenShift 3 : le PaaS privé avec Docker </a></li>
<li><a href="http://blog.octo.com/strategie-de-placement-de-conteneurs-docker-partie-1/" rel="bookmark" title="Stratégies de placement de conteneurs Docker (partie 1)">Stratégies de placement de conteneurs Docker (partie 1) </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/feed/</wfw:commentRss>
		<slash:comments>6</slash:comments>
		</item>
		<item>
		<title>Stratégies de placement de conteneurs Docker (partie 1)</title>
		<link>http://blog.octo.com/strategie-de-placement-de-conteneurs-docker-partie-1/</link>
		<comments>http://blog.octo.com/strategie-de-placement-de-conteneurs-docker-partie-1/#respond</comments>
		<pubDate>Fri, 04 Mar 2016 15:31:59 +0000</pubDate>
		<dc:creator><![CDATA[Arnaud Mazin]]></dc:creator>
				<category><![CDATA[Infrastructure et opérations]]></category>
		<category><![CDATA[compose]]></category>
		<category><![CDATA[consul]]></category>
		<category><![CDATA[containers]]></category>
		<category><![CDATA[conteneurs]]></category>
		<category><![CDATA[Coreos]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[etcd]]></category>
		<category><![CDATA[fleet]]></category>
		<category><![CDATA[hashicorp]]></category>
		<category><![CDATA[Kubernetes]]></category>
		<category><![CDATA[Linux]]></category>
		<category><![CDATA[nomad]]></category>
		<category><![CDATA[swarm]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=60203</guid>
		<description><![CDATA[Les gestionnaires de cluster Docker sont des briques stratégiques lorsqu’il s’agit de déployer des conteneurs à l’échelle, jusqu’en production. Nous travaillons à analyser techniquement ces solutions suivant plusieurs critères : résilience, scalabilité, sécurité, performance… C’est plus précisément sur les stratégies de placement des conteneurs que va porter notre attention dans cette série de deux articles. [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/a-la-decouverte-de-coreos/" rel="bookmark" title="A la découverte de CoreOS">A la découverte de CoreOS </a></li>
<li><a href="http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/" rel="bookmark" title="Docker en production : la bataille sanglante des orchestrateurs de conteneurs">Docker en production : la bataille sanglante des orchestrateurs de conteneurs </a></li>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<style type="text/css"><!--
pre { font-size: 80%; }
code { font-size: 80%; }
pre.commandline { padding:15px; background-color: #020202; color: #e0e0e0;overflow: auto;width: 98%; }
span.hl { color: #c20c0c; font-weight: bold;}
--></style>
<p>Les gestionnaires de cluster Docker sont des briques stratégiques lorsqu’il s’agit de déployer des conteneurs à l’échelle, jusqu’en production.</p>
<p>Nous travaillons à analyser techniquement ces solutions suivant plusieurs critères : résilience, scalabilité, sécurité, performance… C’est plus précisément sur les stratégies de placement des conteneurs que va porter notre attention dans cette série de deux articles.<br />
<span id="more-60203"></span></p>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/02/blog-1.png" alt="blog-1" width="300" height="236" class="aligncenter wp-image-60235" srcset="http://blog.octo.com/wp-content/uploads/2016/02/blog-1-300x236.png 300w, http://blog.octo.com/wp-content/uploads/2016/02/blog-1.png 448w" sizes="(max-width: 300px) 100vw, 300px" /></p>
<p>L’enjeu d’un placement pertinent est primordial car il peut contribuer à offrir une bonne disponibilité des services, des performances, le respect des qualités de service, le tout en optimisant l’utilisation des ressources sous-jacentes. Il est donc nécessaire de pouvoir annoter les conteneurs pour aider le scheduler à prendre les meilleures décisions de placement possibles.</p>
<p>Au menu : l’affinité conteneur-nœud et l’anti-affinité entre conteneurs dans 4 solutions opensource : <a href="https://coreos.com/using-coreos/clustering/">Fleet</a>, <a href="https://www.nomadproject.io/">Nomad</a>, <a href="https://docs.docker.com/swarm/">Swarm</a> et <a href="http://kubernetes.io/">Kubernetes</a>. Nous passerons en revue les opérations de base pour optimiser le placement de nos conteneurs sur chacun de ces produits.</p>
<h1>L’affinité des conteneurs sur les nœuds</h1>
<p>Commençons donc par étudier la capacité à opérer une affinité entre les conteneurs et les nœuds.</p>
<p>Le but de cette affinité peut être de deux ordres :</p>
<ul>
<li>Certains nœuds ont un positionnement réseau particulier qui les rend éligibles à porter des conteneurs particuliers (reverse-proxies en DMZ, applications en zone front, persistance en zone back…)</li>
<li>Certains nœuds ont des caractéristiques techniques (disques low-cost ou ssd, présence dans une zone, région spécifique…)</li>
</ul>
<h2>Démarche</h2>
<p>Avant de mettre en œuvre cette affinité, il est préalablement nécessaire de labelliser les nœuds à l’aide de métadonnées libres. Voyons comment faire cela sur nos quatre candidats, qui pour les besoins de la démonstration, sont installés sur des <a href="https://coreos.com/using-coreos/">CoreOS</a>.</p>
<p>Notre exercice va consister à placer des conteneurs sur des nœuds suivant le type de disques présents sur la machine. Nous allons par conséquent labelliser les nœuds avec une métadonnée <code>disktype</code> qui vaudra <code>hdd</code> ou <code>ssd</code> en fonction des nœuds.</p>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/02/dessins-schedulers-8-e1456483444511.png" alt="Démarche" width="450" height="366" class="aligncenter size-full wp-image-60275" /></p>
<h2>Fleet</h2>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/02/3730757-150x150.png" alt="CoreOS Fleet" width="150" height="150" class="aligncenter size-thumbnail wp-image-60250" srcset="http://blog.octo.com/wp-content/uploads/2016/02/3730757-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/02/3730757-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/02/3730757-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/02/3730757-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/02/3730757-128x128.png 128w, http://blog.octo.com/wp-content/uploads/2016/02/3730757.png 280w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p>Fleet est l&rsquo;orchestrateur livré en standard avec la distribution Linux <a href="https://coreos.com/">CoreOS</a>. Il se présente comme un orchestrateur générique de services distribués (sous forme de conteneurs Docker, <a href="https://coreos.com/rkt/docs/latest/">rkt</a> ou tout autre processus). Il s&rsquo;appuie sur un cluster de nœuds <a href="https://coreos.com/etcd/">etcd</a> pour distribuer sa configuration de façon résiliente.</p>
<h3>Labellisation des nœuds</h3>
<p>Fleet accepte de recevoir des métadonnées au travers d’une variable d’environnement :</p>

<div class="wp_codebox"><table><tr id="p602039"><td class="line_numbers"><pre>1
2
3
</pre></td><td class="code" id="p60203code9"><pre class="ini" style="font-family:monospace;"># /etc/systemd/system/fleet.service.d/<span style="">10</span>-env.conf
<span style="color: #000066; font-weight:bold;"><span style="">&#91;</span>Service<span style="">&#93;</span></span>
<span style="color: #000099;">Environment</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #933;">&quot;FLEET_METADATA=coreos=true,disktype=ssd&quot;</span></pre></td></tr></table></div>

<p>Une fois le redémarrage de Fleet effectué, les nœuds sont visibles avec leurs tags associés</p>
<pre class="commandline">$ fleetctl list-machines
MACHINE IP METADATA
4e58f54e... 10.0.3.73 coreos=true,disktype=ssd
5a73bd14... <span class="hl">10.0.3.61</span> coreos=true,disktype=<span class="hl">hdd</span>
6ad001f1... <span class="hl">10.0.3.62</span> coreos=true,disktype=<span class="hl">hdd</span>
7192a51d... 10.0.3.72 coreos=true,disktype=ssd
d26ecc11... 10.0.3.71 coreos=true,disktype=ssd
ef774ea0... <span class="hl">10.0.3.63</span> coreos=true,disktype=<span class="hl">hdd</span>
</pre>
<h3>Lancement de conteneurs</h3>
<p>La <a href="https://coreos.com/fleet/docs/latest/unit-files-and-scheduling.html">définition d&rsquo;un job Fleet</a> peut alors utiliser cette nouvelle métadonnée <code>disktype</code> comme contrainte. Pour rappel, la description d’un job Fleet est au format des <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html">units systemd</a> auquel est ajoutée une section spécifique <code>[X-Fleet]</code>.</p>

<div class="wp_codebox"><table><tr id="p6020310"><td class="line_numbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="code" id="p60203code10"><pre class="ini" style="font-family:monospace;"># my-nginx@.service
<span style="color: #000066; font-weight:bold;"><span style="">&#91;</span>Unit<span style="">&#93;</span></span>
<span style="color: #000099;">Description</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">My NGinx server</span>
<span style="color: #000099;">After</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">docker.service</span>
<span style="color: #000099;">Requires</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">docker.service</span>
&nbsp;
<span style="color: #000066; font-weight:bold;"><span style="">&#91;</span>Service<span style="">&#93;</span></span>
<span style="color: #000099;">TimeoutStartSec</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">0</span>
<span style="color: #000099;">ExecStartPre</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">-/usr/bin/docker kill my-nginx</span>
<span style="color: #000099;">ExecStartPre</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">-/usr/bin/docker rm my-nginx</span>
<span style="color: #000099;">ExecStartPre</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">/usr/bin/docker pull nginx</span>
<span style="color: #000099;">ExecStart</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">/usr/bin/docker run --rm --name my-nginx -p 80 nginx</span>
<span style="color: #000099;">ExecStop</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">/usr/bin/docker stop my-nginx</span>
&nbsp;
<span style="color: #000066; font-weight:bold;"><span style="">&#91;</span>X-Fleet<span style="">&#93;</span></span>
<span style="color: #000099;">MachineMetadata</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #660066;">disktype=hdd</span></pre></td></tr></table></div>

<p>Il est alors possible de lancer plusieurs instances de l&rsquo;unit avec la commande :</p>
<pre class="commandline">$ for i in {1..4}; do fleetctl start my-nginx@$i.service; done
Unit my-nginx@1.service inactive
Unit my-nginx@1.service launched on 4e58f54e.../<span class="hl">10.0.3.63</span>
Unit my-nginx@2.service inactive
Unit my-nginx@2.service launched on d26ecc11.../<span class="hl">10.0.3.61</span>
Unit my-nginx@3.service inactive
Unit my-nginx@3.service launched on 4e58f54e.../<span class="hl">10.0.3.63</span>
Unit my-nginx@4.service inactive
Unit my-nginx@4.service launched on 7192a51d.../<span class="hl">10.0.3.62</span>
</pre>
<p>Les traces du lancement des units semblent montrer que le scheduler a fait le travail. A posteriori, il est toujours possible de vérifier le placement des conteneurs créés :</p>
<pre class="commandline">
$ fleetctl list-units
UNIT MACHINE ACTIVE SUB
my-nginx@1.service 4e58f54e.../<span class="hl">10.0.3.63</span> active running
my-nginx@2.service d26ecc11.../<span class="hl">10.0.3.61</span> active running
my-nginx@3.service 4e58f54e.../<span class="hl">10.0.3.63</span> active running
my-nginx@4.service 7192a51d.../<span class="hl">10.0.3.62</span> active running
</pre>
<h2>Nomad</h2>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/02/nomad-150x150.png" alt="Nomad" width="150" height="150" class="aligncenter size-thumbnail wp-image-60260" srcset="http://blog.octo.com/wp-content/uploads/2016/02/nomad-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/02/nomad-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/02/nomad-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/02/nomad-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/02/nomad-128x128.png 128w, http://blog.octo.com/wp-content/uploads/2016/02/nomad.png 214w" sizes="(max-width: 150px) 100vw, 150px" /><br />
Nomad est le moteur de cluster de <a href="https://www.hashicorp.com">HashiCorp</a> (créateur de Vagrant, Terraform, Consul…). C&rsquo;est un moteur de cluster nativement dc-aware (conscient des problématique de localisation des nœuds dans les datacenters) qui s&rsquo;intègre simplement avec <a href="https://www.consul.io/">Consul</a>. Il est capable de lancer indifféremment des conteneurs Docker ou d&rsquo;autres types d&rsquo;exécutables au travers de différents <a href="https://www.nomadproject.io/docs/drivers/index.html">task drivers</a>.</p>
<h3>Labellisation des nœuds</h3>
<p>La configuration du client (ou nœud ou agent) permet d’ajouter une section <code>meta</code> avec des propriétés libres :</p>

<div class="wp_codebox"><table><tr id="p6020311"><td class="line_numbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="code" id="p60203code11"><pre class="javascript" style="font-family:monospace;">log_level <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;INFO&quot;</span>
data_dir <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;/var/lib/nomad&quot;</span>
bind_addr <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;0.0.0.0&quot;</span>
advertise <span style="color: #009900;">&#123;</span>
  rpc <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;10.0.3.84:4647&quot;</span>
<span style="color: #009900;">&#125;</span>
client <span style="color: #009900;">&#123;</span>
  enabled <span style="color: #339933;">=</span> <span style="color: #003366; font-weight: bold;">true</span>
  servers <span style="color: #339933;">=</span> <span style="color: #009900;">&#91;</span> <span style="color: #3366CC;">&quot;10.0.3.81:4647&quot;</span><span style="color: #339933;">,</span> <span style="color: #3366CC;">&quot;10.0.3.82:4647&quot;</span><span style="color: #339933;">,</span> <span style="color: #3366CC;">&quot;10.0.3.83:4647&quot;</span> <span style="color: #009900;">&#93;</span>
  node_id <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;coreos-nomad-client1&quot;</span>
  options <span style="color: #009900;">&#123;</span>
    driver.<span style="color: #660066;">whitelist</span> <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;docker&quot;</span>
  <span style="color: #009900;">&#125;</span>
  meta <span style="color: #009900;">&#123;</span>
    disktype <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;hdd&quot;</span>
  <span style="color: #009900;">&#125;</span>
<span style="color: #009900;">&#125;</span></pre></td></tr></table></div>

<p>Les metadata des nœuds ne sont pas visibles au travers de la commande <code>nomad node-status</code>, mais un simple <code>curl</code> sur l’API Nomad permet tout de même de vérifier notre labellisation :</p>
<pre class="commandline">
$ curl -sfq http://127.1:4646/v1/node/coreos-nomad-client1 | jq .Meta
{
  "disktype": "hdd"
}
</pre>
<h3>Lancement de conteneurs</h3>
<p>Lors de la soumission d&rsquo;un <a href="https://www.nomadproject.io/docs/jobspec/">job</a>, il est possible de préciser notre contrainte de placement au travers du bloc <code>constraint</code> :</p>

<div class="wp_codebox"><table><tr id="p6020312"><td class="line_numbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
</pre></td><td class="code" id="p60203code12"><pre class="javascript" style="font-family:monospace;">job <span style="color: #3366CC;">&quot;my-service&quot;</span> <span style="color: #009900;">&#123;</span>
  datacenters <span style="color: #339933;">=</span> <span style="color: #009900;">&#91;</span><span style="color: #3366CC;">&quot;dc1&quot;</span><span style="color: #009900;">&#93;</span>
&nbsp;
  group <span style="color: #3366CC;">&quot;webs&quot;</span> <span style="color: #009900;">&#123;</span>
    count <span style="color: #339933;">=</span> <span style="color: #CC0000;">3</span>
    constraint <span style="color: #009900;">&#123;</span>
      attribute <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;$meta.disktype&quot;</span>
      value <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;hdd&quot;</span>
    <span style="color: #009900;">&#125;</span>
&nbsp;
    task <span style="color: #3366CC;">&quot;frontend&quot;</span> <span style="color: #009900;">&#123;</span>
      driver <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;docker&quot;</span>
      config <span style="color: #009900;">&#123;</span>
        image <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;nginx&quot;</span>
        port_map <span style="color: #009900;">&#123;</span> http <span style="color: #339933;">=</span> <span style="color: #CC0000;">80</span> <span style="color: #009900;">&#125;</span>
      <span style="color: #009900;">&#125;</span>
      service <span style="color: #009900;">&#123;</span>
        port <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;http&quot;</span>
        tags <span style="color: #339933;">=</span> <span style="color: #009900;">&#91;</span> <span style="color: #3366CC;">&quot;http&quot;</span> <span style="color: #009900;">&#93;</span>
        check <span style="color: #009900;">&#123;</span>
          <span style="color: #000066;">name</span> <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;alive&quot;</span>
          type <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;http&quot;</span>
          path <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;/&quot;</span>
          protocol <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;http&quot;</span>
          interval <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;10s&quot;</span>
          timeout <span style="color: #339933;">=</span> <span style="color: #3366CC;">&quot;2s&quot;</span>
        <span style="color: #009900;">&#125;</span>
      <span style="color: #009900;">&#125;</span>
      resources <span style="color: #009900;">&#123;</span>
        cpu <span style="color: #339933;">=</span> <span style="color: #CC0000;">500</span>
        memory <span style="color: #339933;">=</span> <span style="color: #CC0000;">128</span>
        network <span style="color: #009900;">&#123;</span>
          mbits <span style="color: #339933;">=</span> <span style="color: #CC0000;">10</span>
          port <span style="color: #3366CC;">&quot;http&quot;</span> <span style="color: #009900;">&#123;</span> <span style="color: #009900;">&#125;</span>
        <span style="color: #009900;">&#125;</span>
      <span style="color: #009900;">&#125;</span>
    <span style="color: #009900;">&#125;</span>
  <span style="color: #009900;">&#125;</span>
<span style="color: #009900;">&#125;</span></pre></td></tr></table></div>

<p>La soumission du job dans Nomad nous montre que le placement a lancé les conteneurs sur le seul nœud qui répond à la contrainte :</p>
<pre class="commandline">
$ nomad run job.hcl
==&gt; Monitoring evaluation "010099c5-b186-b951-b89e-67ba08eb4ccb"
Evaluation triggered by job "my-service"
Allocation "56258a1d-a861-9f40-23bc-5984936a2aa3" created: node "<span class="hl">coreos-nomad-client1</span>", group "webs"
Allocation "86222b27-69d7-4ea2-aee9-c14a8aa484e4" created: node "<span class="hl">coreos-nomad-client1</span>", group "webs"
Allocation "eb585d75-61d2-9ec5-18c7-b3be83b76a71" created: node "<span class="hl">coreos-nomad-client1</span>", group "webs"
Evaluation status changed: "pending" -&gt; "complete"
==&gt; Evaluation "010099c5-b186-b951-b89e-67ba08eb4ccb" finished with status "complete"
</pre>
<p>La confirmation nous est donnée par la commande de détail du job en cours :</p>
<pre class="commandline">
$ nomad status my-service
ID = my-service
Name = my-service
Type = service
Priority = 50
Datacenters = dc1
Status =

==&gt; Evaluations
ID Priority TriggeredBy Status
010099c5-b186-b951-b89e-67ba08eb4ccb 50 job-register complete

==&gt; Allocations
ID EvalID NodeID TaskGroup Desired Status
56258a1d-a861-9f40-23bc-5984936a2aa3 010099c5-b186-b951-b89e-67ba08eb4ccb <span class="hl">coreos-nomad-client1</span> webs run running
86222b27-69d7-4ea2-aee9-c14a8aa484e4 010099c5-b186-b951-b89e-67ba08eb4ccb <span class="hl">coreos-nomad-client1</span> webs run running
eb585d75-61d2-9ec5-18c7-b3be83b76a71 010099c5-b186-b951-b89e-67ba08eb4ccb <span class="hl">coreos-nomad-client1</span> webs run running
</pre>
<h2>Swarm</h2>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/02/docker-swarm-hero2-150x150.png" alt="Swarm" width="150" height="150" class="aligncenter size-thumbnail wp-image-60253" srcset="http://blog.octo.com/wp-content/uploads/2016/02/docker-swarm-hero2-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/02/docker-swarm-hero2-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/02/docker-swarm-hero2-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/02/docker-swarm-hero2-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/02/docker-swarm-hero2-128x128.png 128w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><a href="https://www.docker.com/products/docker-swarm">Docker Swarm</a> est l&rsquo;orchestrateur de <a href="https://www.docker.com/">Docker Inc</a>. Il a la particularité d&rsquo;exposer une API compatible avec celle de <a href="https://www.docker.com/products/docker-engine">Docker Engine</a>, permettant une réutilisation native des clients Docker, comme <a href="https://www.docker.com/products/docker-compose">Docker Compose</a>.</p>
<h3>Labellisation des nœuds</h3>
<p>La labellisation du nœud s’effectue en ajoutant l’option <code>--label</code> sur la ligne de commande du démon Docker :</p>

<div class="wp_codebox"><table><tr id="p6020313"><td class="line_numbers"><pre>1
2
3
</pre></td><td class="code" id="p60203code13"><pre class="ini" style="font-family:monospace;"># /etc/systemd/system/docker.service.d/<span style="">10</span>-env.conf
<span style="color: #000066; font-weight:bold;"><span style="">&#91;</span>Service<span style="">&#93;</span></span>
<span style="color: #000099;">Environment</span><span style="color: #000066; font-weight:bold;">=</span><span style="color: #933;">&quot;DOCKER_OPTS=-H=0.0.0.0:2376 -H unix:///var/run/docker.sock --cluster-advertise eth0:2376 --cluster-store etcd://10.0.3.30:2379 --label disktype=hdd&quot;</span></pre></td></tr></table></div>

<p>Une fois les démons redémarrés, il est possible de vérifier que les swarm masters ont intégrés la présence de ce label sur les nœuds :</p>
<pre class="commandline">
$ docker info
Containers: 0
 Running: 0
 Paused: 0
 Stopped: 0
Images: 0
Role: replica
Primary: 10.0.3.33:2375
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 <span class="hl">coreos-swarm-node1</span>: 10.0.3.34:2376
  └ Status: Healthy
  └ Containers: 0
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: <span class="hl">disktype=hdd</span>, executiondriver=native-0.2, kernelversion=4.4.1-coreos, operatingsystem=CoreOS 955.0.0, storagedriver=overlay
  └ Error: (none)
  └ UpdatedAt: 2016-02-16T21:57:05Z
 <span class="hl">coreos-swarm-node2</span>: 10.0.3.35:2376
  └ Status: Healthy
  └ Containers: 0
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: <span class="hl">disktype=ssd</span>,executiondriver=native-0.2, kernelversion=4.4.1-coreos, operatingsystem=CoreOS 955.0.0, storagedriver=overlay
  └ Error: (none)
  └ UpdatedAt: 2016-02-16T21:56:51Z
 <span class="hl">coreos-swarm-node3</span>: 10.0.3.36:2376
  └ Status: Healthy
  └ Containers: 0
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: <span class="hl">disktype=hdd</span>,executiondriver=native-0.2, kernelversion=4.4.1-coreos, operatingsystem=CoreOS 955.0.0, storagedriver=overlay
  └ Error: (none)
  └ UpdatedAt: 2016-02-16T21:56:46Z
Plugins:
 Volume:
 Network:
Kernel Version: 4.4.1-coreos
Operating System: linux
Architecture: amd64
CPUs: 3
Total Memory: 3.068 GiB
Name: coreos-swarm-master1
Experimental: true
</pre>
<h3>Lancement de conteneurs</h3>
<p>La syntaxe de contraintes d’affinité ou anti-affinité de Swarm est décrite dans la documentation comme des <a href="https://docs.docker.com/swarm/scheduler/filter/">filtres</a>. Elle est injectée dans Swarm sous forme de pseudo variables d’environnement associées aux conteneurs :</p>
<pre class="commandline">
$ docker run -d -P -e <span class="hl">constraint:disktype==hdd</span> --name nginx1 nginx
0083a290e6cd82259a13f53932cbda59a4f420880111380f2980e1917c712b3f
$ docker run -d -P -e <span class="hl">constraint:disktype==hdd</span> --name nginx2 nginx
fba57999d5d9a70da6e7b03f06d62232742bea2420e4b970b38c40d1eb4c4587
$ docker run -d -P -e <span class="hl">constraint:disktype==hdd</span> --name nginx3 nginx
f0cd897bbe09b7467e5b9e85592e3c0942a8656925bc1b3643d1157a3c51570a
</pre>
<p>Vérifions que le scheduleur a honoré la contrainte :</p>
<pre class="commandline">
$ docker ps --format='{{ .ID }} {{ .Image }} {{ .Names }}'
f0cd897bbe09 nginx <span class="hl">coreos-swarm-node3</span>/nginx3
fba57999d5d9 nginx <span class="hl">coreos-swarm-node3</span>/nginx2
0083a290e6cd nginx <span class="hl">coreos-swarm-node1</span>/nginx1
</pre>
<p>Nous sommes bien en présence de conteneurs qui ne tournent que sur les nœuds répondant à la contrainte.</p>
<h2>Kubernetes</h2>
<p><img src="http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-150x150.png" alt="Kubernetes" width="150" height="150" class="aligncenter size-thumbnail wp-image-60254" srcset="http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-150x150.png 150w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-300x300.png 300w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-1024x1024.png 1024w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-32x32.png 32w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-64x64.png 64w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-96x96.png 96w, http://blog.octo.com/wp-content/uploads/2016/02/21_d3cvm-128x128.png 128w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><a href="http://kubernetes.io/">Kubernetes</a> est l&rsquo;orchestrateur de conteneurs écrit par Google. Il est le fruit d&rsquo;années d&rsquo;expérience du Géant du Web dans l&rsquo;utilisation à très grande échelle de conteneurs Linux. Il est capable de lancer des conteneurs Docker ou <a href="https://coreos.com/rkt/docs/latest/">rkt</a>.</p>
<h3>Labellisation des nœuds</h3>
<p>La labellisation des nœuds peut être effectuée dans Kubernetes à n’importe quel moment via la ligne de commande :</p>
<pre class="commandline">
$ kubectl label no/10.0.3.71 <span class="hl">disktype=ssd</span>
$ kubectl label no/10.0.3.72 <span class="hl">disktype=hdd</span>
$ kubectl label no/10.0.3.73 <span class="hl">disktype=hdd</span>
</pre>
<p>La vérification est possible simplement en listant les nœuds du cluster.</p>
<pre class="commandline">
$ kubectl get nodes
NAME LABELS STATUS AGE
10.0.3.71 <span class="hl">disktype=ssd</span>,kubernetes.io/hostname=10.0.3.71 Ready 3h
10.0.3.72 <span class="hl">disktype=hdd</span>,kubernetes.io/hostname=10.0.3.72 Ready 3h
10.0.3.73 <span class="hl">disktype=hdd</span>,kubernetes.io/hostname=10.0.3.73 Ready 3h
$ kubectl get nodes -l disktype=hdd
NAME LABELS STATUS AGE
10.0.3.72 <span class="hl">disktype=hdd</span>,kubernetes.io/hostname=<span class="hl">10.0.3.72</span> Ready 3h
10.0.3.73 <span class="hl">disktype=hdd</span>,kubernetes.io/hostname=<span class="hl">10.0.3.73</span> Ready 3h
</pre>
<h3>Lancement de conteneurs</h3>
<p>La définition d&rsquo;un pod ou d&rsquo;un ReplicationController avec des contraintes de placement s’effectue au travers de l’attribut <code>NodeSelector</code> :</p>

<div class="wp_codebox"><table><tr id="p6020314"><td class="line_numbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td class="code" id="p60203code14"><pre class="javascript" style="font-family:monospace;">apiVersion<span style="color: #339933;">:</span> v1
kind<span style="color: #339933;">:</span> ReplicationController
metadata<span style="color: #339933;">:</span>
  labels<span style="color: #339933;">:</span>
    run<span style="color: #339933;">:</span> my<span style="color: #339933;">-</span>nginx
  <span style="color: #000066;">name</span><span style="color: #339933;">:</span> my<span style="color: #339933;">-</span>nginx
  <span style="color: #003366; font-weight: bold;">namespace</span><span style="color: #339933;">:</span> <span style="color: #003366; font-weight: bold;">default</span>
spec<span style="color: #339933;">:</span>
  replicas<span style="color: #339933;">:</span> <span style="color: #CC0000;">2</span>
  selector<span style="color: #339933;">:</span>
    run<span style="color: #339933;">:</span> my<span style="color: #339933;">-</span>nginx
  template<span style="color: #339933;">:</span>
    metadata<span style="color: #339933;">:</span>
      labels<span style="color: #339933;">:</span>
        run<span style="color: #339933;">:</span> my<span style="color: #339933;">-</span>nginx
    spec<span style="color: #339933;">:</span>
      containers<span style="color: #339933;">:</span>
      <span style="color: #339933;">-</span> image<span style="color: #339933;">:</span> nginx
        <span style="color: #000066;">name</span><span style="color: #339933;">:</span> my<span style="color: #339933;">-</span>nginx
        ports<span style="color: #339933;">:</span>
        <span style="color: #339933;">-</span> containerPort<span style="color: #339933;">:</span> <span style="color: #CC0000;">80</span>
          protocol<span style="color: #339933;">:</span> TCP
      nodeSelector<span style="color: #339933;">:</span>
        disktype<span style="color: #339933;">:</span> hdd</pre></td></tr></table></div>

<p>Pour créer le ReplicationController :</p>
<pre class="commandline">
$ kubectl create -f rc.yaml
</pre>
<p>Pour vérifier le placement de pods créés :</p>
<pre class="commandline">
$ kubectl get podes -o wide
NAME READY STATUS RESTARTS AGE NODE
my-nginx-8td6t 1/1 Running 1 2h <span class="hl">10.0.3.72</span>
my-nginx-cx34v 1/1 Running 1 2h <span class="hl">10.0.3.73</span>
</pre>
<h2>Conclusion</h2>
<p>Les quatre produits testés montrent une capacité tout à fait correcte à gérer des affinités avec les nœuds :</p>
<table>
<tr>
<th></th>
<th>Fleet</th>
<th>Nomad</th>
<th>Swarm</th>
<th>Kubernetes</th>
</tr>
<tr>
<th>Version testée</th>
<td>0.11.5</td>
<td>0.2.3</td>
<td>1.1.1</td>
<td>1.1.7</td>
</tr>
<tr>
<th>Affinité aux nœuds</th>
<td>oui</td>
<td>oui</td>
<td>oui</td>
<td>oui</td>
</tr>
<tr>
<th>Labellisation des nœuds à chaud</th>
<td>non</td>
<td>non</td>
<td>non</td>
<td>oui</td>
</tr>
<tr>
<th>mot-clé dans la description des jobs</th>
<td><code>MachineMetaData</code></td>
<td><code>contraint</code></td>
<td><code>constraint</code></td>
<td><code>nodeSelector</code></td>
</tr>
</table>
<p></p>
<h3>Remarques</h3>
<p>En cas d’impossibilité de satisfaire les contraintes, le comportement des schedulers se traduira différemment en fonction des moteurs : Nomad et Kubernetes acceptent la création, en espérant pouvoir la satisfaire plus tard, Swarm échoue directement, Fleet bloque la commande jusqu’à ce que la contrainte soit satisfaite.</p>
<p>Nous avons poussé l&rsquo;exercice jusqu&rsquo;à tester le comportement des clusters en cas de déplacement des labels des nœuds. À l’exception de Fleet, la relabellisation des nœuds ne déclenche pas le déplacement des pods existants, mais interviendra lors des prochaines demandes de scheduling. L’administrateur est donc amené à manuellement re-soumettre les jobs ou détruire les conteneurs mal placés en cas de changement de la labels.</p>
<h3>Pour aller plus loin</h3>
<p>Pour aller plus loin sur les contraintes d’affinité sur les nœuds ou si vos besoins s’avèrent plus compliqués que cet exemple, n&rsquo;hésitez pas à aller creuser dans les documentations ou le code source des projets.</p>
<p>Nous verrons dans un prochain article dans quelle mesure les moteurs de cluster permettent également des règles d’anti-affinité entre conteneurs.</p>
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/a-la-decouverte-de-coreos/" rel="bookmark" title="A la découverte de CoreOS">A la découverte de CoreOS </a></li>
<li><a href="http://blog.octo.com/docker-en-production-la-bataille-sanglante-des-orchestrateurs-de-conteneurs/" rel="bookmark" title="Docker en production : la bataille sanglante des orchestrateurs de conteneurs">Docker en production : la bataille sanglante des orchestrateurs de conteneurs </a></li>
<li><a href="http://blog.octo.com/la-ruee-vers-le-conteneur/" rel="bookmark" title="La Ruée vers le conteneur">La Ruée vers le conteneur </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/strategie-de-placement-de-conteneurs-docker-partie-1/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Petit-déjeuner : La Blockchain – mercredi 9 mars</title>
		<link>http://blog.octo.com/petit-dejeuner-la-blockchain-mercredi-9-mars/</link>
		<comments>http://blog.octo.com/petit-dejeuner-la-blockchain-mercredi-9-mars/#respond</comments>
		<pubDate>Tue, 16 Feb 2016 14:46:13 +0000</pubDate>
		<dc:creator><![CDATA[Anne-Sophie Varnier]]></dc:creator>
				<category><![CDATA[Archi & techno]]></category>
		<category><![CDATA[Évènement]]></category>
		<category><![CDATA[Sécurité]]></category>
		<category><![CDATA[Stratégie digitale]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=59643</guid>
		<description><![CDATA[Plongez au coeur des enjeux technologiques, économiques et sociétaux du 21° siècle En participant à ce petit-déjeuner, vous y verrez plus clair sur la technologie considérée comme « The Next Disruptive Technology », comme l&#8217;a été le web dans les années 90.   On parle beaucoup de la Blockchain mais peu savent vraiment identifier ce qui se [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/spark-summit-2015/" rel="bookmark" title="Spark summit 2015">Spark summit 2015 </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<h3>Plongez au coeur des enjeux technologiques, économiques et sociétaux du 21° siècle</h3>
<p>En participant à ce petit-déjeuner, vous y verrez plus clair sur la technologie considérée comme « The Next Disruptive Technology », comme l&rsquo;a été le web dans les années 90.</p>
<p><img class="wp-image-59692 aligncenter" src="http://blog.octo.com/wp-content/uploads/2016/02/ptit_dej_blockchain_site-300x151.png" alt="" width="758" height="381" srcset="http://blog.octo.com/wp-content/uploads/2016/02/ptit_dej_blockchain_site-300x151.png 300w, http://blog.octo.com/wp-content/uploads/2016/02/ptit_dej_blockchain_site.png 780w" sizes="(max-width: 758px) 100vw, 758px" /> <span id="more-59643"></span></p>
<p>On parle beaucoup de la <strong>Blockchain</strong> mais peu savent vraiment identifier ce qui se cache derrière ce &laquo;&nbsp;buzz word&nbsp;&raquo;. Pourtant il est aujourd’hui nécessaire d’en avoir une idée précise car cette technologie est amenée à changer notre manière d’évoluer et d’agir au sein de la société dans les prochaines années.</p>
<p>La <strong>« technologie Blockchain »</strong> est une base de données distribuée, comme un « grand livre », qui récapitule un ensemble de transactions protégées contre la falsification. Les transactions reposent sur cette chaîne de bloc, cet historique,<strong> infalsifiable, auto-régulé et public</strong>. Le maître mot de la Blockchain c’est la <strong>transparence</strong> puisque tout le monde peut bénéficier des informations dont elle dispose.</p>
<p>Historiquement, la Blockchain a déjà joué un rôle, notamment dans la crise des <em>Subprimes</em> en 2008, au travers du <strong>Bitcoin</strong>. L’objectif était alors de prendre le relais de la confiance accordée aux autorités centrales pour faire de la banque sans les banques.</p>
<p>Cependant, elle a depuis <strong>élargi ses horizons</strong> et n’est plus seulement réservée aux transferts financiers mais à un nombre de secteurs bien plus important, aussi bien privés que publics, tels que les secteurs de la <strong>santé</strong>, de <strong>l’assurance</strong> mais aussi de <strong>l’art</strong>.</p>
<p><strong>A l’occasion de ce petit déjeuner, nous allons tenter de répondre à plusieurs questions afin de : </strong></p>
<ul>
<li>Comprendre le fonctionnement de la Blockchain mais aussi pointer ses contraintes et ses limites</li>
<li>Déterminer la maturité des technologies, indiquer où est-ce que nous nous situons</li>
<li>Voir si, dans votre secteur d’activité, vous avez besoin de la technologie Blockchain et quels sont les « use case »</li>
</ul>
<p>Ce petit-déjeuner s’adresse à tous les curieux qui veulent saisir au plus tôt les enjeux d’une technologie qui se promet un avenir aussi marquant que le web, mais aussi aux directions qui souhaitent anticiper les enjeux de la Blockchain, comprendre ce qu’elle signifie vraiment et voir comment elle pourrait permettre de réduire les coûts d’opération et les infrastructures de transaction de certaines entreprises.</p>
<p style="text-align: center;"><a href="http://bit.ly/1ORkIuV">Cliquez ici pour vous inscrire au petit-déjeuner &laquo;&nbsp;La Blockchain&nbsp;&raquo;</a></p>
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/spark-summit-2015/" rel="bookmark" title="Spark summit 2015">Spark summit 2015 </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/petit-dejeuner-la-blockchain-mercredi-9-mars/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Réduire la durée d’un build Android</title>
		<link>http://blog.octo.com/reduisez-la-duree-de-votre-build-android/</link>
		<comments>http://blog.octo.com/reduisez-la-duree-de-votre-build-android/#respond</comments>
		<pubDate>Fri, 29 Jan 2016 07:30:29 +0000</pubDate>
		<dc:creator><![CDATA[Rémi Pradal]]></dc:creator>
				<category><![CDATA[Archi & techno]]></category>
		<category><![CDATA[Android]]></category>
		<category><![CDATA[Continuous integration]]></category>
		<category><![CDATA[Déploiement continu]]></category>
		<category><![CDATA[Gradle]]></category>
		<category><![CDATA[Intégration continue]]></category>
		<category><![CDATA[Mobile]]></category>
		<category><![CDATA[Mobilité]]></category>
		<category><![CDATA[plateforme Android]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=59358</guid>
		<description><![CDATA[La durée d’exécution d’un projet est une métrique que tout développeur Android devrait surveiller de près. En effet, même si celui-ci a une grande confiance dans le code qu’il produit, il sera amené à réexécuter le projet plusieurs fois par jour. Lors du développement d’un projet, il est important pour le développeur de pouvoir constater [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/developper-application-parrallelement-sur-iphone-android/" rel="bookmark" title="Développer une application parallèlement sur iPhone et Android">Développer une application parallèlement sur iPhone et Android </a></li>
<li><a href="http://blog.octo.com/applications-mobiles-multi-plateformes-les-approches-phonegap-et-titanium-mobile/" rel="bookmark" title="Applications mobiles multi-plateformes: les approches PhoneGap et Titanium Mobile">Applications mobiles multi-plateformes: les approches PhoneGap et Titanium Mobile </a></li>
<li><a href="http://blog.octo.com/quelles-interfaces-pour-les-voitures-de-demain-offre/" rel="bookmark" title="Quelles interfaces pour les voitures de demain ? (1/3)">Quelles interfaces pour les voitures de demain ? (1/3) </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>La durée d’exécution d’un projet est une métrique que tout développeur Android devrait surveiller de près. En effet, même si celui-ci a une grande confiance dans le code qu’il produit, il sera amené à réexécuter le projet plusieurs fois par jour. Lors du développement d’un projet, il est important pour le développeur de <strong>pouvoir constater rapidement le résultat de ses modifications</strong>. Dans le cas contraire, il peut se produire deux choses : soit le développeur <em>se déconcentre</em> (parce qu’il regarde ses mails par exemple), soit il revient à son code en <em>oubliant de suivre</em> les effets de sa dernière exécution.</p>
<p>Cette problématique peut paraître exagérée dans le cas d’un &laquo;&nbsp;petit&nbsp;&raquo; projet, compilable en moins de 30 secondes. Mais lorsque le nombre de lignes de code est élevé, elle devient bien réelle.</p>
<p>Nous pouvons découper l’exécution en deux étapes : la compilation et le déploiement. Puisqu’il est difficile de réduire la durée du déploiement (sauf à exécuter l’application dans un émulateur), cet article se concentre sur les leviers actionnables pour <strong>réduire la durée de compilation</strong>.<br />
<span id="more-59358"></span></p>
<h2>Diagnostiquer le temps de compilation</h2>
<p>Nous pouvons définir deux types de durée de compilation :</p>
<ul>
<li>La durée de <strong>compilation &laquo;&nbsp;à partir de zéro&nbsp;&raquo;</strong>. Il s’agit de la durée nécessaire pour exécuter un projet pour la première fois (ou lorsqu’on lance un <code>gradlew clean</code> avant d’exécuter le projet).</li>
<li>La durée de <strong>compilation &laquo;&nbsp;incrémentale&nbsp;&raquo;</strong>. Il s’agit de la durée minimale de compilation après une très petite modification du code, par exemple commenter une ligne de code.</li>
</ul>
<p>Le but est de réduire la durée de compilation exécution après exécution : nous viserons donc une diminution de la durée de compilation &laquo;&nbsp;incrémentale&nbsp;&raquo;. Les prochaines mentions de la durée de compilation feront référence à la durée de compilation &laquo;&nbsp;incrémentale&nbsp;&raquo; telle que définie précédemment. Réduire la durée d’une compilation &laquo;&nbsp;à partir de zéro&nbsp;&raquo; présente certes un intérêt, mais ce n’est pas un genre de compilation que nous lançons fréquemment (par exemple, nous nettoierons le projet ou changerons de branche une à deux fois par jour). Au contraire, l’<em>expérience développeur</em> sera grandement améliorée en réduisant la durée de compilation &laquo;&nbsp;incrémentale&nbsp;&raquo;, puisque le développeur relance cette opération plusieurs dizaines de fois par jour.</p>
<p>Pour mesurer la durée de compilation nous pouvons utiliser la très utile option <code>–profile</code> de Gradle. Cette option génère un rapport des durées de chaque sous-tâche exécutée. Par exemple, si vous exécutez la ligne de commande <code>gradlew assembleDebug –profile</code>, Gradle va générer un rapport dans <code>build/reports/profile-[date-de-la-build]</code>. La capture d’écran qui suit montre un exemple de rapport généré sur un « gros » projet.</p>
<p><img src="http://i.imgur.com/cQ7aAaw.png" alt="Exemple de rapport Gradle" /></p>
<p>Nous y distinguons les principales étapes de compilation d’une application :</p>
<ul>
<li><strong>Configuration</strong> : d’ordinaire très rapide (quelques secondes), sa durée dépend de la complexité de votre script Gradle.</li>
<li><strong>Résolution des dépendances</strong> : presque toujours instantanée car les dépendances sont mises en cache sur votre ordinateur, même si vous avez lancé un « clean » avant. Elle peut prendre plus de temps si c’est la toute première compilation du projet ou si vous ajoutez/modifiez une dépendance dans votre <code>build.gradle</code>. Dans ce cas, la durée ne dépendra que du nombre de librairies appelées et du débit de votre connexion internet.</li>
<li><strong>Exécution des tâches</strong> : l’étape la plus longue. Elle comprend les tâches de compilation, de dexing et de nombreuses de sous-tâches dépendant des tâches principales et du contexte. Certaines sous-tâches sont bien plus longues que d’autres : la précédente capture d’écran montre que celles relatives au multidexing sont les plus chronophages.</li>
</ul>
<p>Dans la majorité des cas, l’exécution des tâches représente une part très élevée de la durée totale. Par exemple, dans le process de compilation dont est extraite la capture, l’exécution des différentes taches de la troisième étape prend 42 secondes sur un total de 50. Nous en concluons que c’est en travaillant sur ce point que nous obtiendrons un gain substantiel.</p>
<h2>Configurer son IDE et son Gradle</h2>
<p>Il existe plusieurs astuces à connaître pour réduire notre durée de compilation Gradle, nous les retrouvons facilement sur StackOverflow. Voici une compilation des meilleures qui précise pour chacune : en quoi l’astuce est utile et les cas où elle n’apporte aucun gain.</p>
<h3>Gradle daemon</h3>
<p>Ajouter <code>org.gradle.daemon=true</code> dans le fichier <code>gradle.properties</code>.</p>
<p>Vous rencontrerez souvent ce conseil. Ceci permet de lancer Gradle avant d’exécuter la première commande Gradle. Le gain sur la compilation peut s’élever à quelques secondes.</p>
<p>Cette solution n’est utile que si nous utilisons la ligne de commande pour toutes les compilations lancées. Android Studio utilise nativement le Gradle daemon [6] depuis longtemps ce qui rend cette astuce inutile dans la plupart des cas.</p>
<h3>Compilation parallèle</h3>
<p>Ajouter <code>org.gradle.parallel=true</code> dans le fichier <code>gradle.properties</code>.</p>
<p>Ce paramètre Gradle permet la compilation de modules en parallèle. Il n’est donc utile que si votre projet est composé de plusieurs modules. Plus la répartition des durées de compilation entre les modules est homogène, meilleur sera le gain sur la durée globale de compilation.</p>
<p>Notons que cette fonctionnalité est encore expérimentale : en l’activant, vous vous exposez donc à des comportements inattendus.</p>
<h3>Configuration à la demande</h3>
<p>Ajouter <code>org.gradle.configureondemand=true</code> dans le fichier <code>gradle.properties</code>.</p>
<p>Cette option aura un impact sur l’étape de « configuration » mentionnée dans la première partie de cet article. Si nous l’activons, l’étape de configuration d’un module donné ne sera faite que si le module joue un rôle dans la tâche Gradle que vous souhaitez exécuter. De la même manière que l’option de compilation en parallèle, cette option ne sera utile que si notre projet est scindé en plusieurs. À moins que nos scripts Gradle ne soient très complexes (ou qu’ils n’exécutent des tâches consommatrices comme un appel réseau), nous ne gagnerons que quelques secondes sur notre durée de compilation.</li>
<h3>Travail hors-ligne</h3>
<p>Dans Android Studio, cliquer sur le menu « Android Studio », puis sur &laquo;&nbsp;Preferences&nbsp;&raquo;. Dans l’arborescence, aller dans &laquo;&nbsp;Build, Execution, Deployment&nbsp;&raquo; -> &laquo;&nbsp;Build tools&nbsp;&raquo; -> &laquo;&nbsp;Gradle&nbsp;&raquo;. Cocher &laquo;&nbsp;Offline work&nbsp;&raquo;.</p>
<p>Le nom de cette option parle d’elle-même ! Le gain peut être fort si nous utilisons une mauvaise connexion internet. Suivant la configuration de notre <code>build.gradle</code>, la compilation peut faire des appels réseaux (vérifier si une bibliothèque dispose d’une nouvelle version). En mode hors-ligne, Gradle utilisera les versions mises en cache. Pour ajouter une nouvelle dépendance, nous devrons désactiver l’option.</p>
<h2>Régler sa cible minimale à 21</h2>
<p>Le contexte dans lequel cette astuce est la plus utile est probablement celui d’un gros projet nécessitant du multidexing et dont la <code>minSdkVersion</code> est strictement inférieure à 21.</p>
<p>Une des évolutions intéressantes dans le processus de compilation apporté par la version 21 du SDK Android (Lollipop) a été l’introduction de Android Runtime (ART). ART et son précurseur Dalvik sont les Machines Java Virtuelles (JVM) sur mesure d’Android. Elles sont compatibles l’une avec l’autre : si votre application a une minSdkVersion de 15 (par exemple), alors les fichiers dex générés pourront être exécutés autant sur ART que sur Dalvik. D’autre part, si votre application a une version minimale de SDK de 21, des optimisations spécifiques à ART peuvent être employées lors de la compilation de l’app. L’une d’entre elles, très utile, est la suivante : ART ne requiert pas un fichier dex principal contenant toutes les classes appelées avant le <code>MultiDex.install()</code>. Ainsi, on peut sauter l’étape, très coûteuse en temps, d’identification des classes à inclure dans le fichier dex principal.<br />
La page de documentation MultiDex d’Android developers [1] donne de nombreuses explications sur toutes les optimisations apportées par ART.</p>
<p>Bien entendu, il ne serait pas admissible de passer tous nos gros projets à un SDK min de 21 ! Nous devons donc trouver un moyen d’avoir plusieurs configurations de compilation différentes. Nous pourrions en avoir une première réglée sur notre SDK min de base, que nous utiliserions pour générer l’APK à déployer en production ; et une autre utilisée par les développeurs lorsqu’ils souhaitent lancer des compilations incrémentales rapides.</p>
<p>Une solution évidente serait d’employer une fonction de Gradle bien connue des développeurs : <code>buildTypes</code>. Malheureusement, il n’est pas (encore) possible de préciser un SDK min pour un certain type de compilation [2]. Nous devons donc utiliser une autre fonction puissante du plugin Android Gradle : les flavors.</p>
<h3>Ciblage de SDK min spécifiques grâce aux flavors</h3>
<p>Les flavors permettent aux développeurs d’avoir différentes configurations de compilation, de ressources ou même de code, s’ils veulent être capables de générer des APK aux caractéristiques différentes. Ceci peut être utile si nous souhaitons générer facilement deux applications partageant le même code source mais sous des marques différentes.</p>
<p>La syntaxe d’un fichier <code>build.gradle</code> utilisant des flavors pour avoir deux configurations de compilation, une de type incrémentale rapide et une normale, est la suivante :</p>
<p><script src="https://gist.github.com/rpradal/6da44bd3a894c660f4e0.js"></script></p>
<p>En conséquence de quoi, le numéro de notre variante de compilation est dupliqué. En choisissant la variante <code>fastBuildDebug</code>, le temps de compilation s’en trouvera significativement réduit. Si nous souhaitons voir à quoi ressemble votre app sur un appareil pre-Lollipop, c’est toujours possible, il nous suffit de choisir la variante <code>regularDebug</code>. De même, la variante que nous avons choisie pour notre application de production est désormais <code>regularProd</code>.</p>
<h3>Gérer un projet ayant déjà plusieurs flavors</h3>
<p>La méthode présentée n’est pas adaptée à une application qui a déjà différentes flavors. Pour la suite, imaginons que les flavors déjà présentes dans votre projet sont <code>brandA</code> et <code>brandB</code>. Si nous utilisons le code ci-dessus, nous ne pouvons pas avoir une compilation rapide présentant des caractéristiques identiques à celles spécifiées par <code>brandA</code>.</p>
<p>Par chance, il existe une solution à ce problème : utiliser les flavors multidimensionnelles [3]. Les flavors multidimensionnelles permettent de créer plusieurs jeux distincts de flavors. Lors de la génération de la variante de compilation, Gradle ne réalisera pas la substitution de deux flavors présentant un id de dimension différent ; à la place, il fera une juxtaposition. </p>
<p>Le script Gradle ci-dessous montre comment utiliser les flavors multidimensionnelles :</p>
<p><script src="https://gist.github.com/rpradal/46b8acec2487fe7fcf22.js"></script></p>
<p>En considérant que nous avons deux types de compilation, debug et prod, nous nous retrouvons avec 8 (=2x2x2) variantes de compilation différentes traduisant les combinaisons possibles de configuration.</p>
<h3>Résultats et limites de cette méthode</h3>
<p>Changer le SDK min réduit considérablement la durée de compilation. Pour un gros projet, comptant environ 150k lignes de code, cette méthode réduit le temps de compilation incrémentale de 2:30 à 1:20. Cette réduction peut être constatée sur toutes les machines : nous avons fait la même analyse avec un autre ordinateur et obtenu un résultat similaire, passant de 3:00 à 1:45.</p>
<p>Pour autant, cette méthode présente quelques inconvénients : elle nous oblige à complexifier la configuration de la compilation. De fait, si nous employons un nom de tâche explicite dans nos scripts Gradle ou dans notre intégration continue (CI), nous devrons répercuter les changements dans chacune de ces références.</p>
<p>De plus, cette méthode double le nombre de tâches. Ainsi, si nous utilisons des tâches agnostiques aux variantes de compilation dans notre CI, telles que <code>gradlew test</code>, la durée de ce job sera plus ou moins doublée. Et pour cause, ces commandes sont lancées pour chaque variante de compilation… Ceci peut se résoudre facilement en n’appelant pas les tâches agnostiques aux variantes de compilation, mais nous devrons alors modifier la configuration de votre CI, ce qui peut s’avérer douloureux.</p>
<h2>Fonctionnalités à venir : système de compilation Jack &amp; Jill, Android Studio instant run</h2>
<p>Il se pourrait que de futures fonctionnalités aient un impact sur la durée de compilation. La plus significative étant probablement la nouvelle chaîne de compilation Android Jack &#038; Jill [4], et Android Studio instant run apportée par la version 2.0 [5].</p>
<h3>Système de compilation Jack &amp; Jill</h3>
<p>Jack &amp; Jill est la nouvelle chaîne de compilation (toolchain) développé par Google. Le but est de remplacer le système actuel, composé de deux étapes complexes &laquo;&nbsp;javac&nbsp;&raquo; et &laquo;&nbsp;dex&nbsp;&raquo; correspondant respectivement à la conversion des fichiers <code>.java</code> en <code>.class</code>, et à la conversion des <code>.class</code> en <code>.dex</code> (le format exécutable que la JVM Android, ART ou Dalvick, saura lire).</p>
<p>Le nouveau compileur Jack est capable de compiler directement les fichiers <code>.class</code> en <code>.dex</code>. Jill est un outil qui convertit des fichiers <code>.jar</code> existants (générés par la toolchain standard) en fichiers directement utilisable par le compilateur Jack. </p>
<p>Le diagramme qui suit synthétise les entrées et sorties de ce nouveau système de compilation.</p>
<p><center><img src="http://android-france.fr/wp-content/uploads/2014/12/nexus2cee_jack_jill_thumb.png" alt="Système de compilation Jack &amp; Jill" /></center></p>
<p>Jack facilite la compilation incrémentale. En conséquence, l’utilisation de cette nouvelle toolchain devrait réduire le temps de compilation. Il est déjà possible d’essayer cette toolchain d’une façon très simple : il nous suffit d’ajouter <code>useJack = true</code> à l’intérieur de notre <code>buildType</code> ou de notre bloc de flavor.</p>
<p>Après quelques tests sur différents projets, nous n’avons pu compiler que quelques fois : dans la plupart des projets, nous avons rencontré des erreurs au cours de la synchronisation Gradle, en particulier sur les gros projets.</p>
<p>Si cette nouvelle toolchain est plutôt prometteuse, elle reste trop expérimentale à ce jour : nous ne pouvons pas encore compter sur elle pour réduire la durée de compilation des projets actuels.</p>
<h3>Android Studio instant run</h3>
<p>Instant run est une fonctionnalité disponible dans Android Studio 2.0 (encore en preview) [7]. Elle permet de pousser dans un émulateur les modifications d’une application de façon quasi instantanée. Est-ce la solution ultime à nos problèmes de durée de compilation ? Ce pourrait être le cas puisque, sur le papier, cette fonctionnalité ne présente aucun inconvénient par rapport aux techniques expliquées précédemment, et elle est bien plus pratique à l’usage.</p>
<p>Pour autant, instant run ne semble pas encore parfaitement stable : il arrive que le code modifié soit indiqué comme ayant été &laquo;&nbsp;poussé&nbsp;&raquo; alors que la modification n’a pas réellement été appliquée dans l’émulateur. Cette fonctionnalité est actuellement stable dans le cas d’un échange à chaud de ressources ou de fichier XML. C’est une grande amélioration car en général nous lançons de nombreuses compilations incrémentales lorsque nous modifions les fichiers XML.</p>
<h2>Conclusion</h2>
<p>La durée de compilation est une métrique que nous avons tout intérêt à suivre avec attention. Il est très facile de la laisser s’allonger au fur et à mesure que grossit l’application, et ce, sans même s’en rendre compte.</p>
<p>Il existe plusieurs manières de réduire la durée de compilation et d’être ainsi plus efficace dans notre développement. Aucune astuce n’est universelle : il convient d’identifier où se produit l’engorgement dans le déroulé de notre compilation, et d’appliquer la méthode la plus adaptée.</p>
<p>Nous avons vu que de futures fonctionnalités pourraient constituer d’excellentes solutions à cette problématique. Si les astuces &laquo;&nbsp;stables&nbsp;&raquo; ne sont pas suffisantes, gardons un œil sur leur évolution et guettons si elles deviennent suffisamment stables pour pouvoir être utilisées au quotidien.</p>
<h2>References</h2>
<p>[1] <a href="http://developer.android.com/tools/building/multidex.html#dev-build" target="_blank">http://developer.android.com/tools/building/multidex.html#dev-build</a><br />
[2] <a href="https://code.google.com/p/android/issues/detail?id=80650" target="_blank">https://code.google.com/p/android/issues/detail?id=80650</a><br />
[3] <a href="http://tools.android.com/tech-docs/new-build-system/user-guide#TOC-Multi-flavor-variants" target="_blank">http://tools.android.com/tech-docs/new-build-system/user-guide#TOC-Multi-flavor-variants</a><br />
[4] <a href="http://tools.android.com/tech-docs/jackandjill" target="_blank">http://tools.android.com/tech-docs/jackandjill</a><br />
[5] <a href="http://android-developers.blogspot.fr/2015/11/android-studio-20-preview.html" target="_blank">http://android-developers.blogspot.fr/2015/11/android-studio-20-preview.html</a><br />
[6] <a href="https://plus.google.com/+AndroidDevelopers/posts/ECrb9VQW9XP" target="_blank">https://plus.google.com/+AndroidDevelopers/posts/ECrb9VQW9XP</a><br />
[7] <a href="http://android-developers.blogspot.fr/2015/11/android-studio-20-preview.html" target="_blank">http://android-developers.blogspot.fr/2015/11/android-studio-20-preview.html</a></p>
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/developper-application-parrallelement-sur-iphone-android/" rel="bookmark" title="Développer une application parallèlement sur iPhone et Android">Développer une application parallèlement sur iPhone et Android </a></li>
<li><a href="http://blog.octo.com/applications-mobiles-multi-plateformes-les-approches-phonegap-et-titanium-mobile/" rel="bookmark" title="Applications mobiles multi-plateformes: les approches PhoneGap et Titanium Mobile">Applications mobiles multi-plateformes: les approches PhoneGap et Titanium Mobile </a></li>
<li><a href="http://blog.octo.com/quelles-interfaces-pour-les-voitures-de-demain-offre/" rel="bookmark" title="Quelles interfaces pour les voitures de demain ? (1/3)">Quelles interfaces pour les voitures de demain ? (1/3) </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/reduisez-la-duree-de-votre-build-android/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Compte-Rendu du petit-déjeuner “Le réactif”</title>
		<link>http://blog.octo.com/compte-rendu-du-petit-dejeuner-le-reactif/</link>
		<comments>http://blog.octo.com/compte-rendu-du-petit-dejeuner-le-reactif/#comments</comments>
		<pubDate>Thu, 28 Jan 2016 13:55:16 +0000</pubDate>
		<dc:creator><![CDATA[Philippe Prados]]></dc:creator>
				<category><![CDATA[Archi & techno]]></category>
		<category><![CDATA[Évènement]]></category>
		<category><![CDATA[Architecture]]></category>
		<category><![CDATA[Petit-déjeuner]]></category>
		<category><![CDATA[Petit-Déjeuner OCTO]]></category>
		<category><![CDATA[Reactive]]></category>

		<guid isPermaLink="false">http://blog.octo.com/?p=59401</guid>
		<description><![CDATA[Jeudi 21 Janvier, l’équipe en charge des technologies Réactives d’OCTO Technology a présenté sa vision des nouvelles architectures Réactives (Vidéo ici, slide là). &#160; La conférence était découpée en trois parties : Que sont ces nouvelles architectures et pourquoi s’y intéresser ? Un retour d’expérience d’un grand projet réactif, avec des contraintes fortes de scalabilité [&#8230;]<div class='yarpp-related-rss'>

Articles suggested :<ol>
<li><a href="http://blog.octo.com/petit-dejeuner-le-reactif-jeudi-21-janvier/" rel="bookmark" title="Petit-déjeuner : le Réactif &#8211; jeudi 21 janvier">Petit-déjeuner : le Réactif &#8211; jeudi 21 janvier </a></li>
<li><a href="http://blog.octo.com/banque-de-detail-du-futur-scenarios-2020/" rel="bookmark" title="Banque de détail du futur : scénarios 2020">Banque de détail du futur : scénarios 2020 </a></li>
<li><a href="http://blog.octo.com/java-8-est-reactif/" rel="bookmark" title="Java 8 est réactif !">Java 8 est réactif ! </a></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>Jeudi 21 Janvier, l’équipe en charge des technologies Réactives d’OCTO Technology a présenté sa <a href="http://www.octo.com/fr/evenements/114-le-reactif">vision des nouvelles architectures Réactives</a> (<a href="http://tv.octo.com/videos/petit-dejeuner-octo-technology-le-reactif-une-nouvelle-approche-pour-faire-face-aux-defis-de-demain/">Vidéo ici</a>, <a href="http://bit.ly/1Sjhlzp">slide là</a>).</p>
<p>&nbsp;</p>
<p><span id="more-59401"></span> La conférence était découpée en trois parties :</p>
<ul>
<li>Que sont ces nouvelles architectures et pourquoi s’y intéresser ?</li>
<li>Un retour d’expérience d’un grand projet réactif, avec des contraintes fortes de scalabilité et de disponibilité</li>
<li>Des pistes pour gérer la transition vers ces nouvelles approches, au niveau organisation et gestion du changement</li>
</ul>
<p>La pression sur les SI étant de plus en plus forte, les architectures précédentes peinent à répondre aux sollicitations. Des limites physiques infranchissables se rapprochent inexorablement, au niveau mémoire (les GC peinent à gérer de gros volumes), CPU (la fréquence n’augmente plus), disque (compensé en partie par les disques SSD) ou réseau (limité par la vitesse de la lumière).</p>
<p>Les approches réactives proposent d’organiser les architectures autour de la répartition des traitements. Le plus en amont possible, les flux sont distribués vers différentes chaînes de traitements les plus hermétiques possibles. Ainsi, le SI devient scalable et est en capacité de dépasser les limites physiques de chaque chaîne de traitement. De plus, les flux sont géré à l’aide d’événements consommés via une approche asynchrone.</p>
<p>Cela n’est pas sans difficulté : il faut accepter de perdre les notions de transactions, gérer les situations où des traitements s’exécutent sur les mêmes données dans des chaînes de traitements disjoints, et cela sans imposer de verrou (consistance à terme). L’idéal étant de ne jamais avoir de concentration entre les technologies pour organiser l’intégralité du SI.</p>
<p>OCTO insiste sur l’importance d’intégrer ces difficultés dès la phase de conception de l’architecture. Le métier est un élément important pour monter une architecture réactive, que cela soit dans les stratégies de distributions des traitements ou dans l’approche “Design by query” où les tables des bases de données sont organisées suivant les requêtes à appliquer. La dénormalisation des données est la règle.</p>
<p>OCTO propose une architecture <a href="http://blog.octo.com/cqrs-larchitecture-aux-deux-visages-partie-1/">CQRS</a> où les flux de lectures s’effectuent via des services WEB et les flux d’écritures s’effectuent via des messages décrivant les mutations. Les messages sont traités par <a href="http://blog.octo.com/spark-summit-2015/">Spark Streaming</a>. Ce modèle d’architecture permet de mémoriser les mutations dans un Datalake à fin d’analyse de l’historique du SI ou pour le Plan de Reprise d’Activité (PRA) en réinjectant l’intégralité des flux.</p>
<p>Dans la deuxième partie, OCTO a présenté la démarche mise en oeuvre sur un projet et montré les difficultés à atteindre les objectifs de scalabilité et de résilience. L&rsquo;accumulation de technologies présentant ces caractéristiques ne fait pas pour autant une architecture capable de résister au crash de chaque maillon.</p>
<p>Lors d’un test, un flux en légère surpression a été injecté dans le SI. Pendant l’injection, on a provoqué un arrêt brutal d’un serveur puis sa remise en fonctionnement à partir d’une machine vierge. Après un délai raisonnable pour permettre au système de rattraper son retard, les données produites sont analysées pour s’assurer de l&rsquo;innocuité du dysfonctionnement. Des ajustements des paramètres ont été nécessaires pour garantir la résilience de la solution. Dans ce cas précis, un minimum de 23 serveurs sont nécessaires.</p>
<p>Une automatisation totale de la plateforme est indispensable pour gérer ces architectures. Une approche DevOps est nécessaire. Sur le projet cité en exemple c’est <a href="http://blog.octo.com/author/tvigourouxocto-com/">Ansible</a> qui a été choisi pour automatiser le provisionning des environnements, du poste du développeur dans des conteneurs LXC, aux plateformes d’intégration dans le Cloud à la production sur des machines physiques.</p>
<p>Enfin, la dernière partie présentait les difficultés d’organisation et de montée en compétence des équipes. Ces technologies et ces approches étant très éloignées des us et coutumes des SI classique, l’évolution des équipes n’est pas sans douleur.</p>
<div class='yarpp-related-rss'>
<p>Articles suggested :</p><ol>
<li><a href="http://blog.octo.com/petit-dejeuner-le-reactif-jeudi-21-janvier/" rel="bookmark" title="Petit-déjeuner : le Réactif &#8211; jeudi 21 janvier">Petit-déjeuner : le Réactif &#8211; jeudi 21 janvier </a></li>
<li><a href="http://blog.octo.com/banque-de-detail-du-futur-scenarios-2020/" rel="bookmark" title="Banque de détail du futur : scénarios 2020">Banque de détail du futur : scénarios 2020 </a></li>
<li><a href="http://blog.octo.com/java-8-est-reactif/" rel="bookmark" title="Java 8 est réactif !">Java 8 est réactif ! </a></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://blog.octo.com/compte-rendu-du-petit-dejeuner-le-reactif/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
	</channel>
</rss>
